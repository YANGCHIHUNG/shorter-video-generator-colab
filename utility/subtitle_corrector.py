"""
å­—å¹•æ ¡æ­£å·¥å…· - ä½¿ç”¨æ—¢æœ‰æ–‡å­—ä¿®æ­£Whisperç”¢ç”Ÿçš„å­—å¹•éŒ¯å­—
Subtitle Corrector - Use existing text to correct Whisper-generated subtitle errors
"""

import re
import logging
from typing import List, Dict, Tuple, Optional
from fuzzywuzzy import fuzz, process
import difflib

logger = logging.getLogger(__name__)

class SubtitleCorrector:
    """å­—å¹•æ ¡æ­£å™¨ - ä½¿ç”¨åƒè€ƒæ–‡å­—ä¿®æ­£Whisperè½‰éŒ„éŒ¯èª¤"""
    
    def __init__(self, similarity_threshold: int = 70, strict_mode: bool = False):
        """
        åˆå§‹åŒ–å­—å¹•æ ¡æ­£å™¨
        
        Args:
            similarity_threshold: ç›¸ä¼¼åº¦é–¾å€¼ (0-100)ï¼Œé«˜æ–¼æ­¤å€¼æ‰é€²è¡Œæ ¡æ­£
            strict_mode: åš´æ ¼æ¨¡å¼ï¼Œåªåœ¨é«˜ç›¸ä¼¼åº¦æ™‚æ‰æ ¡æ­£
        """
        self.similarity_threshold = similarity_threshold
        self.strict_mode = strict_mode
        logger.info(f"ğŸ”§ SubtitleCorrector initialized with threshold={similarity_threshold}%, strict_mode={strict_mode}")
    
    def correct_subtitle_segments(self, whisper_segments: List[Dict], reference_texts: List[str]) -> List[Dict]:
        """
        æ ¡æ­£å­—å¹•ç‰‡æ®µ
        
        Args:
            whisper_segments: Whisperç”¢ç”Ÿçš„å­—å¹•ç‰‡æ®µ
            reference_texts: åƒè€ƒæ–‡å­—åˆ—è¡¨ï¼ˆæ¯å€‹å…ƒç´ å°æ‡‰ä¸€é /ä¸€æ®µè½ï¼‰
        
        Returns:
            æ ¡æ­£å¾Œçš„å­—å¹•ç‰‡æ®µ
        """
        logger.info(f"ğŸ” Starting subtitle correction for {len(whisper_segments)} segments with {len(reference_texts)} reference texts")
        
        # å°‡åƒè€ƒæ–‡å­—æ‹†åˆ†ç‚ºå¥å­
        all_reference_sentences = []
        for ref_text in reference_texts:
            sentences = self._split_into_sentences(ref_text)
            all_reference_sentences.extend(sentences)
        
        logger.info(f"ğŸ“ Total reference sentences: {len(all_reference_sentences)}")
        
        corrected_segments = []
        correction_stats = {"corrected": 0, "unchanged": 0, "partial": 0}
        
        for i, segment in enumerate(whisper_segments):
            original_text = segment['text'].strip()
            
            if not original_text:
                corrected_segments.append(segment)
                continue
            
            # å°‹æ‰¾æœ€ä½³åŒ¹é…çš„åƒè€ƒæ–‡å­—
            corrected_text, correction_type = self._find_best_correction(
                original_text, all_reference_sentences
            )
            
            # æ›´æ–°çµ±è¨ˆ
            correction_stats[correction_type] += 1
            
            # å‰µå»ºæ ¡æ­£å¾Œçš„ç‰‡æ®µ
            corrected_segment = segment.copy()
            corrected_segment['text'] = corrected_text
            corrected_segment['original_text'] = original_text  # ä¿ç•™åŸå§‹æ–‡å­—
            corrected_segment['correction_type'] = correction_type
            
            if correction_type != "unchanged":
                logger.debug(f"âœï¸ Segment {i+1}: '{original_text[:30]}...' â†’ '{corrected_text[:30]}...' ({correction_type})")
            
            corrected_segments.append(corrected_segment)
        
        logger.info(f"ğŸ“Š Correction completed: {correction_stats['corrected']} corrected, "
                   f"{correction_stats['partial']} partial, {correction_stats['unchanged']} unchanged")
        
        return corrected_segments
    
    def _find_best_correction(self, whisper_text: str, reference_sentences: List[str]) -> Tuple[str, str]:
        """
        ç‚ºå–®å€‹Whisperæ–‡å­—æ‰¾åˆ°æœ€ä½³æ ¡æ­£
        
        Args:
            whisper_text: Whisperè½‰éŒ„çš„æ–‡å­—
            reference_sentences: åƒè€ƒå¥å­åˆ—è¡¨
        
        Returns:
            (æ ¡æ­£å¾Œçš„æ–‡å­—, æ ¡æ­£é¡å‹)
        """
        if not reference_sentences:
            return whisper_text, "unchanged"
        
        # æ¸…ç†æ–‡å­—ç”¨æ–¼æ¯”è¼ƒ
        cleaned_whisper = self._clean_text_for_comparison(whisper_text)
        
        # æ‰¾åˆ°æœ€ç›¸ä¼¼çš„åƒè€ƒå¥å­
        best_match = process.extractOne(
            cleaned_whisper, 
            [self._clean_text_for_comparison(ref) for ref in reference_sentences],
            scorer=fuzz.ratio
        )
        
        if not best_match:
            return whisper_text, "unchanged"
        
        best_score = best_match[1]
        best_index = next(i for i, ref in enumerate(reference_sentences) 
                         if self._clean_text_for_comparison(ref) == best_match[0])
        best_reference = reference_sentences[best_index]
        
        # æ ¹æ“šç›¸ä¼¼åº¦æ±ºå®šæ ¡æ­£ç­–ç•¥
        if best_score >= self.similarity_threshold:
            # é«˜ç›¸ä¼¼åº¦ï¼šç›´æ¥ä½¿ç”¨åƒè€ƒæ–‡å­—
            logger.debug(f"ğŸ¯ High similarity ({best_score}%): using reference text")
            return best_reference, "corrected"
        elif best_score >= 60 and not self.strict_mode:
            # ä¸­ç­‰ç›¸ä¼¼åº¦ï¼šå˜—è©¦éƒ¨åˆ†æ ¡æ­£
            partial_corrected = self._partial_correction(whisper_text, best_reference)
            if partial_corrected != whisper_text:
                logger.debug(f"ğŸ”§ Partial correction ({best_score}%): some words corrected")
                return partial_corrected, "partial"
        
        return whisper_text, "unchanged"
    
    def _partial_correction(self, whisper_text: str, reference_text: str) -> str:
        """
        éƒ¨åˆ†æ ¡æ­£ï¼šä¿®æ­£æ˜é¡¯çš„éŒ¯å­—ä½†ä¿æŒæ™‚é–“è»¸å°æ‡‰
        """
        try:
            # æŒ‰è©åˆ†å‰²
            whisper_words = self._segment_chinese_text(whisper_text)
            reference_words = self._segment_chinese_text(reference_text)
            
            # ä½¿ç”¨åºåˆ—æ¯”å°æ‰¾åˆ°å°æ‡‰é—œä¿‚
            matcher = difflib.SequenceMatcher(None, whisper_words, reference_words)
            
            corrected_words = []
            for tag, i1, i2, j1, j2 in matcher.get_opcodes():
                if tag == 'equal':
                    # ç›¸åŒçš„éƒ¨åˆ†ä¿æŒä¸è®Š
                    corrected_words.extend(whisper_words[i1:i2])
                elif tag == 'replace':
                    # æ›¿æ›çš„éƒ¨åˆ†ï¼šå¦‚æœé•·åº¦ç›¸ä¼¼ï¼Œä½¿ç”¨åƒè€ƒæ–‡å­—
                    whisper_part = whisper_words[i1:i2]
                    reference_part = reference_words[j1:j2]
                    
                    if len(whisper_part) == len(reference_part):
                        corrected_words.extend(reference_part)
                    else:
                        corrected_words.extend(whisper_part)
                elif tag == 'delete':
                    # åˆ é™¤çš„éƒ¨åˆ†ä¿ç•™
                    corrected_words.extend(whisper_words[i1:i2])
                elif tag == 'insert':
                    # æ’å…¥çš„éƒ¨åˆ†è·³é
                    pass
            
            return ''.join(corrected_words)
        
        except Exception as e:
            logger.warning(f"âš ï¸ Partial correction failed: {e}")
            return whisper_text
    
    def _split_into_sentences(self, text: str) -> List[str]:
        """å°‡æ–‡å­—åˆ†å‰²ç‚ºå¥å­"""
        # ä¸­æ–‡å¥å­åˆ†éš”ç¬¦
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\.\!\?ï¼›;]', text)
        return [s.strip() for s in sentences if s.strip()]
    
    def _clean_text_for_comparison(self, text: str) -> str:
        """æ¸…ç†æ–‡å­—ç”¨æ–¼æ¯”è¼ƒï¼ˆç§»é™¤æ¨™é»ç¬¦è™Ÿå’Œç©ºæ ¼ï¼‰"""
        # ç§»é™¤æ‰€æœ‰æ¨™é»ç¬¦è™Ÿå’Œç©ºæ ¼
        cleaned = re.sub(r'[^\w]', '', text)
        return cleaned.lower()
    
    def _segment_chinese_text(self, text: str) -> List[str]:
        """
        ç°¡å–®çš„ä¸­æ–‡æ–‡å­—åˆ†è©ï¼ˆæŒ‰å­—ç¬¦åˆ†å‰²ï¼‰
        åœ¨æ²’æœ‰å°ˆæ¥­åˆ†è©å·¥å…·çš„æƒ…æ³ä¸‹çš„åŸºæœ¬å¯¦ç¾
        """
        # å°æ–¼ä¸­æ–‡ï¼ŒæŒ‰å­—ç¬¦åˆ†å‰²
        # å°æ–¼è‹±æ–‡å’Œæ•¸å­—ï¼Œä¿æŒå®Œæ•´è©å½™
        segments = []
        current_word = ""
        
        for char in text:
            if char.isascii() and char.isalnum():
                # è‹±æ–‡å­—æ¯å’Œæ•¸å­—
                current_word += char
            else:
                # ä¸­æ–‡å­—ç¬¦æˆ–æ¨™é»ç¬¦è™Ÿ
                if current_word:
                    segments.append(current_word)
                    current_word = ""
                if char.strip():  # å¿½ç•¥ç©ºç™½å­—ç¬¦
                    segments.append(char)
        
        if current_word:
            segments.append(current_word)
        
        return segments

class EnhancedWhisperSubtitleGenerator:
    """
    å¢å¼·ç‰ˆWhisperå­—å¹•ç”Ÿæˆå™¨ï¼Œæ•´åˆå­—å¹•æ ¡æ­£åŠŸèƒ½
    """
    
    def __init__(self, original_generator, reference_texts: List[str], 
                 enable_correction: bool = True, correction_threshold: int = 70):
        """
        åˆå§‹åŒ–å¢å¼·ç‰ˆå­—å¹•ç”Ÿæˆå™¨
        
        Args:
            original_generator: åŸå§‹çš„WhisperSubtitleGeneratorå¯¦ä¾‹
            reference_texts: åƒè€ƒæ–‡å­—åˆ—è¡¨
            enable_correction: æ˜¯å¦å•Ÿç”¨å­—å¹•æ ¡æ­£
            correction_threshold: æ ¡æ­£é–¾å€¼
        """
        self.original_generator = original_generator
        self.reference_texts = reference_texts
        self.enable_correction = enable_correction
        
        if enable_correction:
            self.corrector = SubtitleCorrector(
                similarity_threshold=correction_threshold
            )
            logger.info(f"âœ… Enhanced subtitle generator with correction enabled (threshold: {correction_threshold}%)")
        else:
            self.corrector = None
            logger.info("ğŸ“ Enhanced subtitle generator with correction disabled")
    
    def generate_corrected_srt(self, audio_path: str, srt_path: Optional[str] = None, 
                              language: Optional[str] = None) -> str:
        """
        ç”Ÿæˆæ ¡æ­£å¾Œçš„SRTå­—å¹•æª”æ¡ˆ
        
        Args:
            audio_path: éŸ³æª”è·¯å¾‘
            srt_path: è¼¸å‡ºSRTæª”æ¡ˆè·¯å¾‘
            language: èªè¨€ä»£ç¢¼
        
        Returns:
            SRTæª”æ¡ˆè·¯å¾‘
        """
        try:
            logger.info(f"ğŸ¬ Generating corrected subtitles for: {audio_path}")
            
            # ä½¿ç”¨åŸå§‹ç”Ÿæˆå™¨é€²è¡ŒWhisperè½‰éŒ„
            original_srt_path = self.original_generator.generate_srt_from_audio(
                audio_path, srt_path, language
            )
            
            if not self.enable_correction or not self.corrector:
                logger.info("ğŸ“ Correction disabled, returning original SRT")
                return original_srt_path
            
            # è®€å–åŸå§‹SRTå…§å®¹
            segments = self._parse_srt_file(original_srt_path)
            
            # åŸ·è¡Œæ ¡æ­£
            corrected_segments = self.corrector.correct_subtitle_segments(
                segments, self.reference_texts
            )
            
            # ç”Ÿæˆæ ¡æ­£å¾Œçš„SRTæª”æ¡ˆ
            corrected_srt_path = original_srt_path.replace('.srt', '_corrected.srt')
            self._write_corrected_srt(corrected_segments, corrected_srt_path)
            
            logger.info(f"âœ… Corrected SRT saved to: {corrected_srt_path}")
            return corrected_srt_path
            
        except Exception as e:
            logger.error(f"âŒ Error generating corrected subtitles: {e}")
            # è¿”å›åŸå§‹SRTä½œç‚ºå‚™é¸
            return self.original_generator.generate_srt_from_audio(audio_path, srt_path, language)
    
    def _parse_srt_file(self, srt_path: str) -> List[Dict]:
        """è§£æSRTæª”æ¡ˆç‚ºç‰‡æ®µåˆ—è¡¨"""
        segments = []
        
        try:
            with open(srt_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()
            
            blocks = content.split('\n\n')
            
            for block in blocks:
                lines = block.strip().split('\n')
                if len(lines) >= 3:
                    # è§£ææ™‚é–“è»¸
                    time_line = lines[1]
                    start_str, end_str = time_line.split(' --> ')
                    
                    start_seconds = self._timestamp_to_seconds(start_str)
                    end_seconds = self._timestamp_to_seconds(end_str)
                    
                    # æ–‡å­—å…§å®¹
                    text = '\n'.join(lines[2:])
                    
                    segments.append({
                        'start': start_seconds,
                        'end': end_seconds,
                        'text': text
                    })
        
        except Exception as e:
            logger.error(f"âŒ Error parsing SRT file: {e}")
        
        return segments
    
    def _timestamp_to_seconds(self, timestamp: str) -> float:
        """å°‡SRTæ™‚é–“æ ¼å¼è½‰æ›ç‚ºç§’æ•¸"""
        # æ ¼å¼: HH:MM:SS,mmm
        time_part, ms_part = timestamp.split(',')
        h, m, s = map(int, time_part.split(':'))
        ms = int(ms_part)
        
        return h * 3600 + m * 60 + s + ms / 1000.0
    
    def _write_corrected_srt(self, segments: List[Dict], output_path: str):
        """å¯«å…¥æ ¡æ­£å¾Œçš„SRTæª”æ¡ˆ"""
        srt_content = ""
        
        for i, segment in enumerate(segments, 1):
            start_time = self._seconds_to_timestamp(segment['start'])
            end_time = self._seconds_to_timestamp(segment['end'])
            text = segment['text']
            
            srt_content += f"{i}\n"
            srt_content += f"{start_time} --> {end_time}\n"
            srt_content += f"{text}\n\n"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(srt_content)
    
    def _seconds_to_timestamp(self, seconds: float) -> str:
        """å°‡ç§’æ•¸è½‰æ›ç‚ºSRTæ™‚é–“æ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds % 1) * 1000)
        
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"
