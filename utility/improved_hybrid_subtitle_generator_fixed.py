#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ”¹é€²çš„æ··åˆå­—å¹•ç”Ÿæˆå™¨ - æ”¯æ´å­—å¹•é•·åº¦æ§åˆ¶å’Œæ™ºèƒ½æ™‚é–“æˆ³æ˜ å°„
"""

import os
import sys
import tempfile
import subprocess
import logging
import re
from typing import List, Dict, Any, Optional

# è¨­ç½®æ—¥èªŒ
logger = logging.getLogger(__name__)

class ImprovedHybridSubtitleGenerator:
    """æ”¹é€²çš„æ··åˆå­—å¹•ç”Ÿæˆå™¨ - æ™ºèƒ½æ™‚é–“æˆ³æ˜ å°„å’Œå­—å¹•é•·åº¦æ§åˆ¶"""
    
    def __init__(self, model_size: str = "small", traditional_chinese: bool = False, subtitle_length_mode: str = "auto"):
        """
        åˆå§‹åŒ–æ··åˆå­—å¹•ç”Ÿæˆå™¨
        
        Args:
            model_size: Whisper æ¨¡å‹å¤§å° ("tiny", "small", "medium", "large")
            traditional_chinese: æ˜¯å¦ä½¿ç”¨ç¹é«”ä¸­æ–‡
            subtitle_length_mode: å­—å¹•é•·åº¦æ§åˆ¶æ¨¡å¼ ('auto', 'compact', 'standard', 'relaxed')
        """
        self.model_size = model_size
        self.traditional_chinese = traditional_chinese
        self.subtitle_length_mode = subtitle_length_mode
        self._whisper_model = None
        
        # é…ç½®å­—å¹•é•·åº¦åƒæ•¸
        self._configure_length_parameters()
        
        # å°å…¥æ‰€éœ€æ¨¡çµ„
        try:
            import whisper
            self.whisper = whisper
            logger.info(f"âœ… Whisper æ¨¡çµ„è¼‰å…¥æˆåŠŸï¼Œæ¨¡å‹å¤§å°: {model_size}")
        except ImportError:
            logger.error("âŒ ç„¡æ³•å°å…¥ Whisper æ¨¡çµ„")
            raise ImportError("éœ€è¦å®‰è£ openai-whisper: pip install openai-whisper")
        
        try:
            import zhconv
            self.zhconv = zhconv
            logger.info("âœ… ä¸­æ–‡è½‰æ›æ¨¡çµ„è¼‰å…¥æˆåŠŸ")
        except ImportError:
            logger.warning("âš ï¸ ä¸­æ–‡è½‰æ›æ¨¡çµ„æœªå®‰è£ï¼Œå°‡è·³éç¹ç°¡è½‰æ›")
            self.zhconv = None
        
        try:
            import difflib
            self.difflib = difflib
            logger.info("âœ… æ–‡å­—æ¯”å°æ¨¡çµ„è¼‰å…¥æˆåŠŸ")
        except ImportError:
            logger.warning("âš ï¸ æ–‡å­—æ¯”å°æ¨¡çµ„æœªå®‰è£")
            self.difflib = None
        
        try:
            from fuzzywuzzy import fuzz
            self.fuzz = fuzz
            logger.info("âœ… æ¨¡ç³ŠåŒ¹é…æ¨¡çµ„è¼‰å…¥æˆåŠŸ")
        except ImportError:
            logger.warning("âš ï¸ æ¨¡ç³ŠåŒ¹é…æ¨¡çµ„æœªå®‰è£ï¼Œå°‡ä½¿ç”¨åŸºæœ¬æ˜ å°„")
            self.fuzz = None
    
    def _configure_length_parameters(self):
        """æ ¹æ“šå­—å¹•é•·åº¦æ¨¡å¼é…ç½®åƒæ•¸"""
        length_configs = {
            'compact': {
                'max_chars_per_line': 12,
                'max_lines': 2,
                'min_display_time': 1.8
            },
            'standard': {
                'max_chars_per_line': 15,
                'max_lines': 2,
                'min_display_time': 1.5
            },
            'relaxed': {
                'max_chars_per_line': 18,
                'max_lines': 2,
                'min_display_time': 1.2
            },
            'auto': {
                'max_chars_per_line': 15,  # é è¨­å€¼
                'max_lines': 2,
                'min_display_time': 1.5
            }
        }
        
        config = length_configs.get(self.subtitle_length_mode, length_configs['auto'])
        self.max_chars_per_line = config['max_chars_per_line']
        self.max_lines = config['max_lines']
        self.min_display_time = config['min_display_time']
        self.max_chars_total = self.max_chars_per_line * self.max_lines
        
        logger.info(f"ğŸ“ å­—å¹•é•·åº¦é…ç½®: {self.subtitle_length_mode} - "
                   f"æ¯è¡Œ{self.max_chars_per_line}å­—ï¼Œæœ€å¤š{self.max_lines}è¡Œ")
    
    def get_whisper_model(self):
        """ç²å– Whisper æ¨¡å‹å¯¦ä¾‹"""
        if self._whisper_model is None:
            try:
                logger.info(f"ğŸ”„ æ­£åœ¨è¼‰å…¥ Whisper æ¨¡å‹: {self.model_size}")
                self._whisper_model = self.whisper.load_model(self.model_size)
                logger.info(f"âœ… Whisper æ¨¡å‹è¼‰å…¥å®Œæˆ: {self.model_size}")
            except Exception as e:
                logger.error(f"âŒ è¼‰å…¥ Whisper æ¨¡å‹å¤±æ•—: {e}")
                raise e
        return self._whisper_model
    
    def transcribe_audio(self, audio_path: str) -> List[Dict]:
        """ä½¿ç”¨ Whisper è½‰éŒ„éŸ³é »ä¸¦ç²å–æ™‚é–“æˆ³"""
        try:
            model = self.get_whisper_model()
            logger.info(f"ğŸ™ï¸ é–‹å§‹è½‰éŒ„éŸ³é »: {audio_path}")
            
            result = model.transcribe(
                audio_path,
                word_timestamps=True,
                verbose=False
            )
            
            segments = result.get("segments", [])
            logger.info(f"âœ… éŸ³é »è½‰éŒ„å®Œæˆï¼Œç²å¾— {len(segments)} å€‹ç‰‡æ®µ")
            
            return segments
            
        except Exception as e:
            logger.error(f"âŒ éŸ³é »è½‰éŒ„å¤±æ•—: {e}")
            raise e
    
    def _smart_split_text_into_sentences(self, text: str) -> List[str]:
        """æ™ºèƒ½ä¸­æ–‡åˆ†å¥"""
        if not text:
            return []
        
        # ä¸­æ–‡å¥è™Ÿã€æ„Ÿå˜†è™Ÿã€å•è™Ÿç­‰
        sentence_endings = r'[ã€‚ï¼ï¼Ÿï¼›]'
        
        # å…ˆæŒ‰ä¸»è¦æ¨™é»åˆ†å‰²
        sentences = re.split(sentence_endings, text)
        
        # æ¸…ç†ä¸¦é‡çµ„å¥å­ï¼ˆä¿ç•™æ¨™é»ï¼‰
        result_sentences = []
        for i, sentence in enumerate(sentences):
            sentence = sentence.strip()
            if sentence:
                # é‡æ–°æ·»åŠ æ¨™é»ï¼ˆé™¤äº†æœ€å¾Œä¸€å€‹ç©ºå­—ç¬¦ä¸²ï¼‰
                if i < len(sentences) - 1:
                    # æŸ¥æ‰¾åŸæ–‡ä¸­å°æ‡‰çš„æ¨™é»
                    original_pos = sum(len(sentences[j]) for j in range(i + 1)) + i
                    if original_pos < len(text):
                        punct = text[original_pos]
                        sentence += punct
                result_sentences.append(sentence)
        
        # å¦‚æœåˆ†å¥å¤±æ•—ï¼ŒæŒ‰é€—è™Ÿåˆ†å‰²
        if len(result_sentences) <= 1:
            sentences = text.split('ï¼Œ')
            result_sentences = [s.strip() for s in sentences if s.strip()]
        
        logger.info(f"ğŸ“ æ–‡å­—åˆ†å¥å®Œæˆ: {len(result_sentences)} å€‹å¥å­")
        return result_sentences
    
    def _convert_chinese(self, text: str) -> str:
        """ä¸­æ–‡ç¹ç°¡è½‰æ›"""
        if not self.traditional_chinese or not self.zhconv:
            return text
        
        try:
            return self.zhconv.convert(text, 'zh-tw')
        except Exception as e:
            logger.warning(f"âš ï¸ ä¸­æ–‡è½‰æ›å¤±æ•—: {e}")
            return text
        
    def _generate_srt_content(self, segments: List[Dict]) -> str:
        """ç”Ÿæˆ SRT å­—å¹•å…§å®¹ï¼ˆæ”¯æ´é•·å­—å¹•åˆ‡åˆ†ï¼‰"""
        srt_content = ""
        subtitle_index = 1
        
        for segment in segments:
            start_time = segment["start"]
            end_time = segment["end"]
            text = segment["text"]
            
            # åˆ‡åˆ†éé•·çš„å­—å¹•
            split_subtitles = self._split_long_subtitle(text, start_time, end_time)
            
            for sub_segment in split_subtitles:
                srt_start_time = self._format_time(sub_segment["start"])
                srt_end_time = self._format_time(sub_segment["end"])
                sub_text = sub_segment["text"]
                
                srt_content += f"{subtitle_index}\n"
                srt_content += f"{srt_start_time} --> {srt_end_time}\n"
                srt_content += f"{sub_text}\n\n"
                subtitle_index += 1
        
        return srt_content
    
    def _split_long_subtitle(self, text: str, start_time: float, end_time: float) -> List[Dict]:
        """
        åˆ‡åˆ†éé•·çš„å­—å¹•
        
        Args:
            text: åŸå§‹å­—å¹•æ–‡å­—
            start_time: é–‹å§‹æ™‚é–“
            end_time: çµæŸæ™‚é–“
            
        Returns:
            åˆ‡åˆ†å¾Œçš„å­—å¹•ç‰‡æ®µåˆ—è¡¨
        """
        # ä½¿ç”¨é…ç½®çš„å­—å¹•é¡¯ç¤ºåƒæ•¸
        max_chars_per_line = self.max_chars_per_line
        max_lines = self.max_lines
        max_chars_total = self.max_chars_total
        min_display_time = self.min_display_time
        
        # å¦‚æœæ–‡å­—ä¸è¶…éé™åˆ¶ï¼Œç›´æ¥è¿”å›
        if len(text) <= max_chars_total:
            formatted_text = self._format_subtitle_lines(text, max_chars_per_line)
            return [{
                "start": start_time,
                "end": end_time,
                "text": formatted_text
            }]
        
        # åˆ‡åˆ†é•·æ–‡å­—
        segments = []
        total_duration = end_time - start_time
        
        # æ™ºèƒ½åˆ†å¥ï¼šå„ªå…ˆæŒ‰æ¨™é»ç¬¦è™Ÿåˆ‡åˆ†
        sentences = self._smart_split_by_punctuation(text, max_chars_total)
        
        # è¨ˆç®—æ¯å€‹åˆ†æ®µçš„æ™‚é–“
        total_chars = sum(len(sentence) for sentence in sentences)
        current_time = start_time
        
        for i, sentence in enumerate(sentences):
            # æ ¹æ“šå­—å…ƒæ•¸æ¯”ä¾‹åˆ†é…æ™‚é–“
            if total_chars > 0:
                segment_duration = (len(sentence) / total_chars) * total_duration
            else:
                segment_duration = total_duration / len(sentences)
            
            # ç¢ºä¿æœ€å°é¡¯ç¤ºæ™‚é–“
            segment_duration = max(segment_duration, min_display_time)
            
            # è¨ˆç®—çµæŸæ™‚é–“
            segment_end_time = current_time + segment_duration
            
            # æœ€å¾Œä¸€å€‹ç‰‡æ®µå°é½ŠåŸå§‹çµæŸæ™‚é–“
            if i == len(sentences) - 1:
                segment_end_time = end_time
            
            # é€²ä¸€æ­¥åˆ‡åˆ†éé•·çš„å¥å­ï¼ˆå¦‚æœå–®å¥ä»ç„¶å¤ªé•·ï¼‰
            if len(sentence) > max_chars_total:
                sub_segments = self._force_split_long_sentence(
                    sentence, current_time, segment_end_time, max_chars_total
                )
                segments.extend(sub_segments)
                current_time = sub_segments[-1]["end"]
            else:
                # æ ¼å¼åŒ–ç‚ºé›™è¡Œé¡¯ç¤º
                formatted_text = self._format_subtitle_lines(sentence, max_chars_per_line)
                segments.append({
                    "start": current_time,
                    "end": segment_end_time,
                    "text": formatted_text
                })
                current_time = segment_end_time
        
        return segments
    
    def _smart_split_by_punctuation(self, text: str, max_chars: int) -> List[str]:
        """æ ¹æ“šæ¨™é»ç¬¦è™Ÿæ™ºèƒ½åˆ‡åˆ†æ–‡å­—"""
        # ä¸­æ–‡æ¨™é»ç¬¦è™Ÿ
        punctuation_marks = ['ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼›', 'ï¼Œ', 'ã€', 'ï¼š']
        
        sentences = []
        current_sentence = ""
        
        for char in text:
            current_sentence += char
            
            # é‡åˆ°æ¨™é»ç¬¦è™Ÿä¸”é•·åº¦é©ä¸­æ™‚åˆ‡åˆ†
            if char in punctuation_marks and len(current_sentence.strip()) > 0:
                if len(current_sentence) <= max_chars:
                    sentences.append(current_sentence.strip())
                    current_sentence = ""
                # å¦‚æœåŠ ä¸Šæ¨™é»å¾Œä»ç„¶å¤ªé•·ï¼Œå…ˆåˆ‡åˆ†å‰é¢çš„éƒ¨åˆ†
                elif len(current_sentence) > max_chars:
                    # å›é€€åˆ°æ¨™é»å‰
                    pre_punct = current_sentence[:-1].strip()
                    if pre_punct:
                        sentences.append(pre_punct)
                    current_sentence = char  # ä¿ç•™æ¨™é»ç¬¦è™Ÿ
        
        # è™•ç†å‰©é¤˜æ–‡å­—
        if current_sentence.strip():
            sentences.append(current_sentence.strip())
        
        # åˆä½µéçŸ­çš„ç‰‡æ®µ
        return self._merge_short_segments(sentences, max_chars)
    
    def _merge_short_segments(self, sentences: List[str], max_chars: int) -> List[str]:
        """åˆä½µéçŸ­çš„ç‰‡æ®µ"""
        merged = []
        current = ""
        
        for sentence in sentences:
            # å¦‚æœåˆä½µå¾Œä¸è¶…éé™åˆ¶ï¼Œå‰‡åˆä½µ
            if len(current + sentence) <= max_chars:
                current += sentence
            else:
                # ä¿å­˜ç•¶å‰ç‰‡æ®µï¼Œé–‹å§‹æ–°ç‰‡æ®µ
                if current:
                    merged.append(current)
                current = sentence
        
        # æ·»åŠ æœ€å¾Œä¸€å€‹ç‰‡æ®µ
        if current:
            merged.append(current)
        
        return merged
    
    def _force_split_long_sentence(self, sentence: str, start_time: float, end_time: float, max_chars: int) -> List[Dict]:
        """å¼·åˆ¶åˆ‡åˆ†éé•·çš„å¥å­"""
        segments = []
        total_duration = end_time - start_time
        
        # æŒ‰æœ€å¤§å­—å…ƒæ•¸å¼·åˆ¶åˆ‡åˆ†
        parts = []
        for i in range(0, len(sentence), max_chars):
            parts.append(sentence[i:i + max_chars])
        
        # åˆ†é…æ™‚é–“
        current_time = start_time
        for i, part in enumerate(parts):
            # æ ¹æ“šå­—å…ƒæ•¸æ¯”ä¾‹åˆ†é…æ™‚é–“
            part_duration = (len(part) / len(sentence)) * total_duration
            part_end_time = current_time + part_duration
            
            # æœ€å¾Œä¸€å€‹ç‰‡æ®µå°é½ŠçµæŸæ™‚é–“
            if i == len(parts) - 1:
                part_end_time = end_time
            
            # æ ¼å¼åŒ–ç‚ºé›™è¡Œé¡¯ç¤º
            formatted_text = self._format_subtitle_lines(part, self.max_chars_per_line)
            segments.append({
                "start": current_time,
                "end": part_end_time,
                "text": formatted_text
            })
            
            current_time = part_end_time
        
        return segments
    
    def _format_subtitle_lines(self, text: str, max_chars_per_line: int) -> str:
        """å°‡æ–‡å­—æ ¼å¼åŒ–ç‚ºé©åˆçš„è¡Œæ•¸"""
        if len(text) <= max_chars_per_line:
            return text
        
        # å˜—è©¦åœ¨åˆé©çš„ä½ç½®æ–·è¡Œ
        words = list(text)  # ä¸­æ–‡æŒ‰å­—å…ƒè™•ç†
        lines = []
        current_line = ""
        
        for char in words:
            if len(current_line + char) <= max_chars_per_line:
                current_line += char
            else:
                if current_line:
                    lines.append(current_line)
                current_line = char
        
        # æ·»åŠ æœ€å¾Œä¸€è¡Œ
        if current_line:
            lines.append(current_line)
        
        # æœ€å¤šå…©è¡Œï¼Œå¦‚æœè¶…éå‰‡åˆä½µ
        if len(lines) > 2:
            # é‡æ–°åˆ†é…åˆ°å…©è¡Œ
            half_chars = len(text) // 2
            line1 = text[:half_chars]
            line2 = text[half_chars:]
            return f"{line1}\n{line2}"
        else:
            return "\n".join(lines)
    
    def _format_time(self, seconds: float) -> str:
        """å°‡ç§’æ•¸è½‰æ›ç‚º SRT æ™‚é–“æ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        seconds_remainder = seconds % 60
        milliseconds = int((seconds_remainder % 1) * 1000)
        seconds_int = int(seconds_remainder)
        
        return f"{hours:02d}:{minutes:02d}:{seconds_int:02d},{milliseconds:03d}"
    
    def generate_hybrid_subtitles(self, video_path: str, reference_texts: List[str]) -> str:
        """
        ç”Ÿæˆæ”¹é€²çš„æ··åˆå­—å¹•
        
        Args:
            video_path: è¦–é »æ–‡ä»¶è·¯å¾‘
            reference_texts: ç”¨æˆ¶æä¾›çš„åƒè€ƒæ–‡å­—åˆ—è¡¨ï¼ˆæ¯å€‹å…ƒç´ ä»£è¡¨ä¸€é ï¼‰
            
        Returns:
            SRT å­—å¹•æ–‡ä»¶è·¯å¾‘
        """
        try:
            logger.info(f"ğŸ¬ é–‹å§‹ç”Ÿæˆæ··åˆå­—å¹•ï¼Œè¦–é »: {video_path}")
            logger.info(f"ğŸ“„ åƒè€ƒæ–‡å­—é æ•¸: {len(reference_texts)}")
            
            # å¾è¦–é »æå–éŸ³é »
            audio_path = self._extract_audio_from_video(video_path)
            
            # ä½¿ç”¨ Whisper è½‰éŒ„éŸ³é »ç²å–æ™‚é–“æˆ³
            whisper_segments = self.transcribe_audio(audio_path)
            
            # æ˜ å°„ç”¨æˆ¶æ–‡å­—åˆ° Whisper æ™‚é–“ç‰‡æ®µ
            mapped_segments = self._map_text_to_segments(whisper_segments, reference_texts)
            
            # ç”Ÿæˆ SRT å…§å®¹ï¼ˆåŒ…å«é•·å­—å¹•åˆ‡åˆ†ï¼‰
            srt_content = self._generate_srt_content(mapped_segments)
            
            # ä¿å­˜ SRT æ–‡ä»¶
            srt_path = video_path.replace('.mp4', '_hybrid.srt')
            with open(srt_path, 'w', encoding='utf-8') as f:
                f.write(srt_content)
            
            logger.info(f"âœ… æ··åˆå­—å¹•ç”Ÿæˆå®Œæˆ: {srt_path}")
            
            # æ¸…ç†è‡¨æ™‚éŸ³é »æ–‡ä»¶
            if os.path.exists(audio_path):
                os.remove(audio_path)
            
            return srt_path
            
        except Exception as e:
            logger.error(f"âŒ æ··åˆå­—å¹•ç”Ÿæˆå¤±æ•—: {e}")
            raise e
    
    def _extract_audio_from_video(self, video_path: str) -> str:
        """å¾è¦–é »ä¸­æå–éŸ³é »"""
        try:
            # å‰µå»ºè‡¨æ™‚éŸ³é »æ–‡ä»¶
            audio_path = video_path.replace('.mp4', '_temp_audio.wav')
            
            # ä½¿ç”¨ ffmpeg æå–éŸ³é »
            cmd = [
                'ffmpeg', '-i', video_path,
                '-acodec', 'pcm_s16le',
                '-ar', '16000',
                '-ac', '1',
                '-y', audio_path
            ]
            
            logger.info(f"ğŸµ æ­£åœ¨æå–éŸ³é »: {video_path} -> {audio_path}")
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                raise Exception(f"FFmpeg æå–éŸ³é »å¤±æ•—: {result.stderr}")
            
            logger.info(f"âœ… éŸ³é »æå–å®Œæˆ: {audio_path}")
            return audio_path
            
        except Exception as e:
            logger.error(f"âŒ éŸ³é »æå–å¤±æ•—: {e}")
            raise e
    
    def _map_text_to_segments(self, whisper_segments: List[Dict], reference_texts: List[str]) -> List[Dict]:
        """æ˜ å°„ç”¨æˆ¶æ–‡å­—åˆ° Whisper æ™‚é–“ç‰‡æ®µ"""
        mapped_segments = []
        
        if not whisper_segments or not reference_texts:
            return mapped_segments
        
        logger.info(f"ğŸ§  é–‹å§‹æ˜ å°„ï¼š{len(reference_texts)} å€‹ç”¨æˆ¶æ–‡å­— â†’ {len(whisper_segments)} å€‹ Whisper ç‰‡æ®µ")
        
        # å°‡æ‰€æœ‰ç”¨æˆ¶æ–‡å­—åˆ†å‰²æˆå¥å­
        all_sentences = []
        for page_text in reference_texts:
            sentences = self._smart_split_text_into_sentences(page_text)
            all_sentences.extend(sentences)
        
        logger.info(f"ğŸ“ ç¸½å…±åˆ†å‰²å‡º {len(all_sentences)} å€‹å¥å­")
        
        # æ™ºèƒ½æ˜ å°„ç­–ç•¥
        if len(all_sentences) == len(whisper_segments):
            # ä¸€å°ä¸€æ˜ å°„
            for i, sentence in enumerate(all_sentences):
                whisper_seg = whisper_segments[i]
                text = self._convert_chinese(sentence)
                
                mapped_segments.append({
                    "start": whisper_seg["start"],
                    "end": whisper_seg["end"],
                    "text": text
                })
        else:
            # æ¯”ä¾‹åˆ†é…æ˜ å°„
            total_duration = whisper_segments[-1]["end"] - whisper_segments[0]["start"]
            sentence_duration = total_duration / len(all_sentences) if all_sentences else 0
            
            for i, sentence in enumerate(all_sentences):
                start_time = whisper_segments[0]["start"] + (i * sentence_duration)
                end_time = start_time + sentence_duration
                
                # ç¢ºä¿æœ€å¾Œä¸€å€‹å¥å­çš„çµæŸæ™‚é–“èˆ‡ Whisper ä¸€è‡´
                if i == len(all_sentences) - 1:
                    end_time = whisper_segments[-1]["end"]
                
                text = self._convert_chinese(sentence)
                
                mapped_segments.append({
                    "start": start_time,
                    "end": end_time,
                    "text": text
                })
        
        logger.info(f"âœ… æ˜ å°„å®Œæˆï¼Œç”Ÿæˆ {len(mapped_segments)} å€‹å­—å¹•ç‰‡æ®µ")
        return mapped_segments
    
    def embed_subtitles_in_video(self, input_video_path: str, srt_path: str, output_video_path: str, style: str = "default") -> bool:
        """å°‡å­—å¹•åµŒå…¥è¦–é »"""
        try:
            logger.info(f"ğŸ¬ é–‹å§‹åµŒå…¥å­—å¹•: {input_video_path}")
            
            # å­—å¹•æ¨£å¼é…ç½®
            style_configs = {
                "default": "force_style='FontName=Microsoft YaHei,FontSize=24,PrimaryColour=&Hffffff,SecondaryColour=&Hffffff,OutlineColour=&H0,BackColour=&H80000000,Bold=1,Italic=0,Underline=0,StrikeOut=0,ScaleX=100,ScaleY=100,Spacing=0,Angle=0,BorderStyle=1,Outline=2,Shadow=0,Alignment=2,MarginL=10,MarginR=10,MarginV=10'",
                "yellow": "force_style='FontName=Microsoft YaHei,FontSize=24,PrimaryColour=&H00ffff,SecondaryColour=&H00ffff,OutlineColour=&H0,BackColour=&H80000000,Bold=1,Italic=0,Underline=0,StrikeOut=0,ScaleX=100,ScaleY=100,Spacing=0,Angle=0,BorderStyle=1,Outline=2,Shadow=0,Alignment=2,MarginL=10,MarginR=10,MarginV=10'",
                "white_box": "force_style='FontName=Microsoft YaHei,FontSize=24,PrimaryColour=&Hffffff,SecondaryColour=&Hffffff,OutlineColour=&H0,BackColour=&H80000000,Bold=1,Italic=0,Underline=0,StrikeOut=0,ScaleX=100,ScaleY=100,Spacing=0,Angle=0,BorderStyle=3,Outline=1,Shadow=0,Alignment=2,MarginL=10,MarginR=10,MarginV=10'"
            }
            
            style_option = style_configs.get(style, style_configs["default"])
            
            cmd = [
                'ffmpeg',
                '-i', input_video_path,
                '-vf', f"subtitles={srt_path}:{style_option}",
                '-c:a', 'copy',
                '-y', output_video_path
            ]
            
            logger.info(f"ğŸ”§ åŸ·è¡Œ FFmpeg å‘½ä»¤åµŒå…¥å­—å¹•")
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                logger.error(f"âŒ FFmpeg åµŒå…¥å­—å¹•å¤±æ•—: {result.stderr}")
                return False
            
            logger.info(f"âœ… å­—å¹•åµŒå…¥å®Œæˆ: {output_video_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å­—å¹•åµŒå…¥å¤±æ•—: {e}")
            return False
