from google import genai
import edge_tts
from tqdm import tqdm
import time
import itertools
import os
import torch
import numpy as np
from utility.text import *
from kokoro import KPipeline
import soundfile as sf

async def kokoro_tts_example(text, output_dir, filename, voice="zm_yunyang"):
    """
    Generates speech from text using Kokoro's KPipeline and saves it to a specific directory.
    
    :param text: Text to be converted to speech.
    :param output_dir: Directory where the audio file will be saved.
    :param filename: Name of the audio file.
    :param voice: The voice model to use.
    :return: Full path of the saved audio file.
    """
    if not text or text.strip() == "":
        print("âš ï¸ Warning: Received empty text for speech synthesis.")
        return None  # Skip empty text

    # Ensure the output directory exists
    os.makedirs(output_dir, exist_ok=True)
    
    # Define the full file path (using .wav for this example)
    output_file_path = os.path.join(output_dir, filename)
    
    try:
        # Clean the text to remove any problematic characters
        cleaned_text = text.strip()
        if len(cleaned_text) > 1000:
            print(f"âš ï¸ Warning: Text is very long ({len(cleaned_text)} chars), truncating...")
            cleaned_text = cleaned_text[:1000] + "..."
        
        print(f"ğŸ”Š Generating speech using voice: {voice}, Text length: {len(cleaned_text)}")
        
        # Initialize the KPipeline with an explicit repo_id to suppress the warning
        pipeline_instance = KPipeline(lang_code='z', repo_id="hexgrad/Kokoro-82M")
        
        # Create a generator that yields (graphemes, phonemes, audio)
        generator = pipeline_instance(
            cleaned_text, voice=voice, speed=1, split_pattern=r'\n+'
        )
        
        # Merge audio segments (convert Tensors to NumPy arrays if needed)
        audio_segments = []
        for i, (_, _, audio) in enumerate(generator):
            # Check if the audio segment is a Tensor and convert it to a NumPy array
            if isinstance(audio, torch.Tensor):
                audio_np = audio.detach().cpu().numpy()
            else:
                audio_np = audio
            audio_segments.append(audio_np)
        
        if audio_segments:
            # Concatenate the segments along the first dimension
            final_audio = np.concatenate(audio_segments, axis=0)
            sf.write(output_file_path, final_audio, 24000)
            
            # Verify that the file was actually created and has content
            if os.path.exists(output_file_path):
                file_size = os.path.getsize(output_file_path)
                if file_size > 0:
                    print(f"âœ… Successfully saved TTS audio: {output_file_path} ({file_size} bytes)")
                    return output_file_path
                else:
                    print(f"âŒ Error: Audio file {output_file_path} is empty (0 bytes)")
                    return None
            else:
                print(f"âŒ Error: Audio file {output_file_path} was not created")
                return None
        else:
            print("âš ï¸ No audio segments were generated.")
            return None

    except Exception as e:
        print(f"âŒ Error generating speech: {e}")
        print(f"âŒ Text that caused error: {text[:100]}...")
        return None

async def edge_tts_example(text, output_dir, filename, voice="zh-CN-YunxiNeural"):
    """
    Generates speech from text and saves it to a specific directory.
    
    :param text: Text to be converted to speech.
    :param output_dir: Directory where the audio file will be saved.
    :param filename: Name of the audio file.
    :param voice: The voice model to use.
    :return: Full path of the saved audio file.
    """
    if not text or text.strip() == "":
        print("âš ï¸ Warning: Received empty text for speech synthesis.")
        return None  # Skip empty text

    # âœ… Ensure the output directory exists
    os.makedirs(output_dir, exist_ok=True)

    # âœ… Define the full file path
    output_file_path = os.path.join(output_dir, filename)

    # âœ… Generate speech and save it to the file
    try:
        # Clean the text to remove any problematic characters
        cleaned_text = text.strip()
        if len(cleaned_text) > 1000:
            print(f"âš ï¸ Warning: Text is very long ({len(cleaned_text)} chars), truncating...")
            cleaned_text = cleaned_text[:1000] + "..."
        
        print(f"ğŸ’¾ Saving TTS audio to: {output_file_path}")
        print(f"ğŸ”Š Using voice: {voice}, Text length: {len(cleaned_text)}")
        
        # Validate voice parameter for Chinese text
        if any('\u4e00' <= char <= '\u9fff' for char in cleaned_text):  # Check for Chinese characters
            if not voice.startswith(('zh-', 'zh_')):
                print(f"âš ï¸ Warning: Chinese text detected but using non-Chinese voice: {voice}")
                # Auto-correct to Chinese voice
                voice = "zh-TW-YunJheNeural"
                print(f"ğŸ”„ Auto-corrected to Chinese voice: {voice}")
        
        communicate = edge_tts.Communicate(cleaned_text, voice, rate="+20%")
        await communicate.save(output_file_path)
        
        # Add a small delay to ensure file is written
        import asyncio
        await asyncio.sleep(0.2)
        
        # Verify that the file was actually created and has content
        if os.path.exists(output_file_path):
            file_size = os.path.getsize(output_file_path)
            if file_size > 0:
                print(f"âœ… Successfully saved TTS audio: {output_file_path} ({file_size} bytes)")
                return output_file_path
            else:
                print(f"âŒ Error: Audio file {output_file_path} is empty (0 bytes)")
                return None
        else:
            print(f"âŒ Error: Audio file {output_file_path} was not created")
            return None
            
    except Exception as e:
        print(f"âŒ Error saving audio: {e}")
        print(f"âŒ Voice used: {voice}")
        print(f"âŒ Text that caused error: {text[:100]}...")
        return None



def gemini_chat(text_array=None, script=None, clients=None, keys=None, max_retries=100):
    if text_array is None or script is None:
        raise ValueError("script or text_array can't be None")
    
    if (clients is None or len(clients) == 0) and (keys is None or len(keys) == 0):
        raise ValueError("Either clients or keys must be provided")

    # âœ… If only keys are provided, create clients
    if clients is None or len(clients) == 0:
        clients = [genai.Client(api_key=key) for key in keys]

    # âœ… Ensure we have multiple clients to rotate
    client_cycle = itertools.cycle(clients)

    response_array_of_text = []
    count = 0
    for idx, text in enumerate(tqdm(text_array)):
        retries = 0
        client = next(client_cycle)  # Get the first client

        while retries < max_retries:
            try:
                response = client.models.generate_content(
                    model="gemini-2.0-flash",
                    contents=f'''ä»¥ä¸‹æ˜¯æˆ‘å€‘çš„å®Œæ•´è¬›ç¨¿ï¼š{script}  
                    ä»¥ä¸‹æ˜¯ç¬¬ {count} å¼µ Ptt å…§å®¹ï¼Œå‰é¢å¹¾å¼µå·²ç¶“è™•ç†å®Œç•¢ï¼š{text}  
                    è«‹ä»”ç´°é–±è®€ä¸Šè¿°è³‡æ–™ï¼Œä¸¦å¾ä¸­èƒå–èˆ‡æ­¤å¼µæŠ•å½±ç‰‡ç›´æ¥ç›¸é—œçš„é‡é»ï¼Œç”Ÿæˆä¸€æ®µé‡å°è©²æŠ•å½±ç‰‡çš„è¬›ç¨¿ã€‚  
                    è¦æ±‚å¦‚ä¸‹ï¼š  
                    1. å‡è£ä½ æ˜¯è¬›è€…ï¼Œç”¨äººé¡çš„æ–¹å¼è¬›è©±ï¼Œä¸è¦å›‰å”†èˆ‡æŠ•å½±ç‰‡ç„¡é—œçš„è³‡è¨Šã€‚  
                    2. å›æ‡‰å…§å®¹å¿…é ˆåš´æ ¼é™å®šåœ¨è©²æŠ•å½±ç‰‡ç¯„åœå…§ï¼Œä¸å¾—æ“´å±•åˆ°å…¶ä»–éƒ¨åˆ†ï¼Œä¸èƒ½è¬› "å¥½çš„" ... é¿å…è®“äººç™¼ç¾æ­¤ç‚º AI ç”¢ç”Ÿã€‚  
                    3. é¿å…æåˆ°æœƒå¤šä¹…è¬›å®Œã€‚
                    4. ä¸è¦å¿µä¸€äº›ç„¡æ„ç¾©çš„æ±è¥¿ä¾‹å¦‚ï¼šé€£çµ: https://www.ptt.cc/bbs/Beauty/M.1700000000.A.123.html'''
                )
                response_array_of_text.append(remove_markdown(response.text))
                count += 1
                break  # âœ… Successful request; exit retry loop
            except Exception as e:
                error_message = str(e)
                if "RESOURCE_EXHAUSTED" in error_message:
                    wait_time = 2 ** retries  # Exponential backoff
                    print(f"Rate limit reached for current client. Switching client and retrying in {wait_time} seconds...")
                    time.sleep(wait_time)
                    retries += 1
                    client = next(client_cycle)  # ğŸ”„ Rotate to the next client
                else:
                    raise e  # âš ï¸ Other errors should not be retried (e.g., invalid request)
        else:
            raise Exception("Max retries reached. Aborting.")
    
    return response_array_of_text
