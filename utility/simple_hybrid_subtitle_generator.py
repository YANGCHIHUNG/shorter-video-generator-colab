#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç°¡åŒ–çš„æ··åˆå­—å¹•ç”Ÿæˆå™¨ - ä¸ä¾è³´ MoviePy
ä½¿ç”¨ FFmpeg ç›´æ¥è™•ç†è¦–é »å­—å¹•
"""

import os
import sys
import tempfile
import subprocess
import logging
from typing import List, Dict, Any, Optional

# è¨­ç½®æ—¥èªŒ
logger = logging.getLogger(__name__)

class SimpleHybridSubtitleGenerator:
    """ç°¡åŒ–çš„æ··åˆå­—å¹•ç”Ÿæˆå™¨"""
    
    def __init__(self, model_size: str = "small", traditional_chinese: bool = False):
        """
        åˆå§‹åŒ–æ··åˆå­—å¹•ç”Ÿæˆå™¨
        
        Args:
            model_size: Whisper æ¨¡å‹å¤§å° ("tiny", "small", "medium", "large")
            traditional_chinese: æ˜¯å¦ä½¿ç”¨ç¹é«”ä¸­æ–‡
        """
        self.model_size = model_size
        self.traditional_chinese = traditional_chinese
        self._whisper_model = None
        
        # å°å…¥æ‰€éœ€æ¨¡çµ„
        try:
            import whisper
            self.whisper = whisper
            logger.info(f"âœ… Whisper æ¨¡çµ„è¼‰å…¥æˆåŠŸï¼Œæ¨¡å‹å¤§å°: {model_size}")
        except ImportError:
            logger.error("âŒ ç„¡æ³•å°å…¥ Whisper æ¨¡çµ„")
            raise ImportError("éœ€è¦å®‰è£ openai-whisper: pip install openai-whisper")
        
        try:
            import zhconv
            self.zhconv = zhconv
            logger.info("âœ… ä¸­æ–‡è½‰æ›æ¨¡çµ„è¼‰å…¥æˆåŠŸ")
        except ImportError:
            logger.warning("âš ï¸ ä¸­æ–‡è½‰æ›æ¨¡çµ„æœªå®‰è£ï¼Œå°‡è·³éç¹ç°¡è½‰æ›")
            self.zhconv = None
    
    def _load_whisper_model(self):
        """è¼‰å…¥ Whisper æ¨¡å‹"""
        if self._whisper_model is None:
            logger.info(f"ğŸ”„ è¼‰å…¥ Whisper æ¨¡å‹: {self.model_size}")
            self._whisper_model = self.whisper.load_model(self.model_size)
            logger.info("âœ… Whisper æ¨¡å‹è¼‰å…¥å®Œæˆ")
        return self._whisper_model
    
    def _extract_audio_from_video(self, video_path: str) -> str:
        """å¾è¦–é »ä¸­æå–éŸ³é »"""
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_audio:
            temp_audio_path = temp_audio.name
        
        # ä½¿ç”¨ FFmpeg æå–éŸ³é »
        cmd = [
            'ffmpeg', '-i', video_path,
            '-vn', '-acodec', 'pcm_s16le',
            '-ar', '16000', '-ac', '1',
            '-y', temp_audio_path
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            logger.info("âœ… éŸ³é »æå–æˆåŠŸ")
            return temp_audio_path
        except subprocess.CalledProcessError as e:
            logger.error(f"âŒ éŸ³é »æå–å¤±æ•—: {e.stderr}")
            raise
    
    def _transcribe_audio(self, audio_path: str) -> List[Dict[str, Any]]:
        """ä½¿ç”¨ Whisper è½‰éŒ„éŸ³é »"""
        model = self._load_whisper_model()
        
        logger.info("ğŸ¯ é–‹å§‹éŸ³é »è½‰éŒ„...")
        result = model.transcribe(
            audio_path,
            language='zh',  # æŒ‡å®šä¸­æ–‡
            word_timestamps=True
        )
        
        segments = result.get('segments', [])
        logger.info(f"âœ… è½‰éŒ„å®Œæˆï¼Œå…± {len(segments)} å€‹ç‰‡æ®µ")
        
        return segments
    
    def _map_text_to_segments(self, whisper_segments: List[Dict], reference_texts: List[str]) -> List[Dict]:
        """å°‡ç”¨æˆ¶æ–‡å­—æ˜ å°„åˆ° Whisper æ™‚é–“ç‰‡æ®µ"""
        mapped_segments = []
        
        if not whisper_segments:
            logger.warning("âš ï¸ æ²’æœ‰ Whisper ç‰‡æ®µå¯ä¾›æ˜ å°„")
            return mapped_segments
        
        total_duration = whisper_segments[-1]["end"] - whisper_segments[0]["start"]
        
        # è¨ˆç®—æ¯å€‹åƒè€ƒæ–‡å­—æ‡‰åˆ†é…çš„æ™‚é–“
        text_duration = total_duration / len(reference_texts) if reference_texts else 0
        
        for i, text in enumerate(reference_texts):
            start_time = whisper_segments[0]["start"] + (i * text_duration)
            end_time = start_time + text_duration
            
            # ç¢ºä¿æœ€å¾Œä¸€æ®µçš„çµæŸæ™‚é–“èˆ‡ Whisper çµæœä¸€è‡´
            if i == len(reference_texts) - 1:
                end_time = whisper_segments[-1]["end"]
            
            # ä¸­æ–‡è½‰æ›
            final_text = self._convert_chinese(text)
            
            mapped_segments.append({
                "start": start_time,
                "end": end_time,
                "text": final_text
            })
        
        logger.info(f"âœ… æ–‡å­—æ˜ å°„å®Œæˆï¼Œå…± {len(mapped_segments)} å€‹ç‰‡æ®µ")
        return mapped_segments
    
    def _convert_chinese(self, text: str) -> str:
        """ç¹ç°¡ä¸­æ–‡è½‰æ›"""
        if self.traditional_chinese and self.zhconv:
            try:
                return self.zhconv.convert(text, 'zh-tw')
            except Exception as e:
                logger.warning(f"âš ï¸ ä¸­æ–‡è½‰æ›å¤±æ•—: {e}")
                return text
        return text
    
    def _generate_srt_content(self, segments: List[Dict]) -> str:
        """ç”Ÿæˆ SRT å­—å¹•å…§å®¹"""
        srt_content = ""
        
        for i, segment in enumerate(segments, 1):
            start_time = self._format_time(segment["start"])
            end_time = self._format_time(segment["end"])
            text = segment["text"]
            
            srt_content += f"{i}\n"
            srt_content += f"{start_time} --> {end_time}\n"
            srt_content += f"{text}\n\n"
        
        return srt_content
    
    def _format_time(self, seconds: float) -> str:
        """å°‡ç§’æ•¸è½‰æ›ç‚º SRT æ™‚é–“æ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        seconds_remainder = seconds % 60
        milliseconds = int((seconds_remainder % 1) * 1000)
        seconds_int = int(seconds_remainder)
        
        return f"{hours:02d}:{minutes:02d}:{seconds_int:02d},{milliseconds:03d}"
    
    def generate_hybrid_subtitles(self, video_path: str, reference_texts: List[str]) -> str:
        """
        ç”Ÿæˆæ··åˆå­—å¹•
        
        Args:
            video_path: è¦–é »æ–‡ä»¶è·¯å¾‘
            reference_texts: ç”¨æˆ¶æä¾›çš„åƒè€ƒæ–‡å­—åˆ—è¡¨
            
        Returns:
            SRT å­—å¹•æ–‡ä»¶è·¯å¾‘
        """
        logger.info("ğŸš€ é–‹å§‹ç”Ÿæˆæ··åˆå­—å¹•...")
        
        # 1. æå–éŸ³é »
        audio_path = self._extract_audio_from_video(video_path)
        
        try:
            # 2. ä½¿ç”¨ Whisper è½‰éŒ„ç²å–æ™‚é–“æˆ³
            whisper_segments = self._transcribe_audio(audio_path)
            
            # 3. å°‡ç”¨æˆ¶æ–‡å­—æ˜ å°„åˆ°æ™‚é–“ç‰‡æ®µ
            mapped_segments = self._map_text_to_segments(whisper_segments, reference_texts)
            
            # 4. ç”Ÿæˆ SRT å…§å®¹
            srt_content = self._generate_srt_content(mapped_segments)
            
            # 5. ä¿å­˜ SRT æ–‡ä»¶
            srt_path = video_path.replace('.mp4', '_hybrid.srt')
            with open(srt_path, 'w', encoding='utf-8') as f:
                f.write(srt_content)
            
            logger.info(f"âœ… æ··åˆå­—å¹•ç”Ÿæˆå®Œæˆ: {srt_path}")
            return srt_path
            
        finally:
            # æ¸…ç†æš«å­˜éŸ³é »æ–‡ä»¶
            try:
                os.unlink(audio_path)
                logger.info("ğŸ§¹ æš«å­˜éŸ³é »æ–‡ä»¶å·²æ¸…ç†")
            except Exception as e:
                logger.warning(f"âš ï¸ æ¸…ç†æš«å­˜æ–‡ä»¶å¤±æ•—: {e}")
    
    def embed_subtitles_in_video(self, 
                                input_video_path: str, 
                                srt_path: str, 
                                output_video_path: str,
                                subtitle_style: str = "default") -> bool:
        """
        ä½¿ç”¨ FFmpeg å°‡å­—å¹•åµŒå…¥è¦–é »
        
        Args:
            input_video_path: è¼¸å…¥è¦–é »è·¯å¾‘
            srt_path: SRT å­—å¹•æ–‡ä»¶è·¯å¾‘
            output_video_path: è¼¸å‡ºè¦–é »è·¯å¾‘
            subtitle_style: å­—å¹•æ¨£å¼
            
        Returns:
            æˆåŠŸè¿”å› Trueï¼Œå¤±æ•—è¿”å› False
        """
        logger.info("ğŸ¬ é–‹å§‹å°‡å­—å¹•åµŒå…¥è¦–é »...")
        
        # å­—å¹•æ¨£å¼è¨­å®š
        style_options = {
            "default": "FontSize=24,FontName=Microsoft YaHei,PrimaryColour=&Hffffff,BackColour=&H80000000",
            "large": "FontSize=32,FontName=Microsoft YaHei,PrimaryColour=&Hffffff,BackColour=&H80000000",
            "bold": "FontSize=28,FontName=Microsoft YaHei,Bold=1,PrimaryColour=&Hffffff,BackColour=&H80000000"
        }
        
        style = style_options.get(subtitle_style, style_options["default"])
        
        # FFmpeg å‘½ä»¤
        cmd = [
            'ffmpeg',
            '-i', input_video_path,
            '-vf', f"subtitles={srt_path}:force_style='{style}'",
            '-c:a', 'copy',
            '-y', output_video_path
        ]
        
        try:
            logger.info("ğŸ”„ åŸ·è¡Œ FFmpeg å­—å¹•åµŒå…¥...")
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            logger.info("âœ… å­—å¹•åµŒå…¥æˆåŠŸ")
            return True
            
        except subprocess.CalledProcessError as e:
            logger.error(f"âŒ å­—å¹•åµŒå…¥å¤±æ•—: {e.stderr}")
            return False
        except Exception as e:
            logger.error(f"âŒ å­—å¹•åµŒå…¥éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
