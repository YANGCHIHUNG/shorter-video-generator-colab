#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ”¹é€²çš„æ··åˆå­—å¹•ç”Ÿæˆå™¨ - æ”¯æ´å­—å¹•é•·åº¦æ§åˆ¶å’Œæ™ºèƒ½æ™‚é–“æˆ³æ˜ å°„
"""

import os
import sys
import tempfile
import subprocess
import logging
import re
import platform
from typing import List, Dict, Any, Optional

# è¨­ç½®æ—¥èªŒ
logger = logging.getLogger(__name__)

def get_available_chinese_font():
    """
    è·¨å¹³å°æª¢æ¸¬å¯ç”¨çš„ä¸­æ–‡å­—é«”
    Returns:
        str: å­—é«”æ–‡ä»¶è·¯å¾‘æˆ–å­—é«”åç¨±ï¼Œå¦‚æœæ‰¾ä¸åˆ°å‰‡è¿”å› None
    """
    system = platform.system()
    
    if system == "Linux":
        # Linux/Colab ç’°å¢ƒ - æª¢æŸ¥ Noto å­—é«”
        linux_fonts = [
            "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
            "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
            "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf"
        ]
        for font_path in linux_fonts:
            if os.path.exists(font_path):
                logger.info(f"ğŸ”¤ æ‰¾åˆ° Linux å­—é«”: {font_path}")
                return font_path
        logger.warning("âš ï¸ Linux ç’°å¢ƒæœªæ‰¾åˆ°ç†æƒ³ä¸­æ–‡å­—é«”ï¼Œä½¿ç”¨ç³»çµ±é»˜èª")
        return None
        
    elif system == "Windows":
        # Windows ç’°å¢ƒ
        windows_fonts = [
            "C:/Windows/Fonts/msyh.ttc",  # Microsoft YaHei
            "C:/Windows/Fonts/simhei.ttf",  # SimHei
            "C:/Windows/Fonts/simsun.ttc"   # SimSun
        ]
        for font_path in windows_fonts:
            if os.path.exists(font_path):
                logger.info(f"ğŸ”¤ æ‰¾åˆ° Windows å­—é«”: {font_path}")
                return font_path
        return "Microsoft YaHei"  # å­—é«”åç¨±
        
    elif system == "Darwin":  # macOS
        # macOS ç’°å¢ƒ
        macos_fonts = [
            "/System/Library/Fonts/PingFang.ttc",
            "/Library/Fonts/Arial Unicode MS.ttf",
            "/System/Library/Fonts/STHeiti Light.ttc"
        ]
        for font_path in macos_fonts:
            if os.path.exists(font_path):
                logger.info(f"ğŸ”¤ æ‰¾åˆ° macOS å­—é«”: {font_path}")
                return font_path
        return "PingFang SC"  # å­—é«”åç¨±
    
    logger.warning(f"âš ï¸ æœªè­˜åˆ¥çš„ç³»çµ±: {system}ï¼Œä½¿ç”¨é»˜èªå­—é«”")
    return None

class ImprovedHybridSubtitleGenerator:
    """æ”¹é€²çš„æ··åˆå­—å¹•ç”Ÿæˆå™¨ - æ™ºèƒ½æ™‚é–“æˆ³æ˜ å°„å’Œå­—å¹•é•·åº¦æ§åˆ¶"""
    
    def __init__(self, model_size: str = "small", traditional_chinese: bool = False, subtitle_length_mode: str = "auto", chars_per_line: int = 15, max_lines: int = 2):
        """
        åˆå§‹åŒ–æ··åˆå­—å¹•ç”Ÿæˆå™¨ - ç°¡åŒ–ç‰ˆæœ¬ï¼Œå®Œå…¨ä½¿ç”¨ç”¨æˆ¶è¼¸å…¥æ–‡å­—
        
        Args:
            model_size: Whisper æ¨¡å‹å¤§å° ("tiny", "small", "medium", "large")
            traditional_chinese: æ˜¯å¦ä½¿ç”¨ç¹é«”ä¸­æ–‡
            subtitle_length_mode: å­—å¹•é•·åº¦æ§åˆ¶æ¨¡å¼ ('auto', 'compact', 'standard', 'relaxed')
            chars_per_line: æ¯è¡Œæœ€å¤§å­—æ•¸
            max_lines: æœ€å¤§è¡Œæ•¸
        """
        self.model_size = model_size
        self.traditional_chinese = traditional_chinese
        self.subtitle_length_mode = subtitle_length_mode
        self._whisper_model = None
        
        # è¨­ç½®å­—å¹•é¡¯ç¤ºåƒæ•¸
        self.chars_per_line = chars_per_line
        self.max_lines = max_lines
        self.min_display_time = 1.5  # æœ€å°é¡¯ç¤ºæ™‚é–“ï¼ˆç§’ï¼‰
        
        # æ ¹æ“šæ¨¡å¼èª¿æ•´åƒæ•¸
        if subtitle_length_mode == 'compact':
            self.chars_per_line = min(chars_per_line, 12)
            self.min_display_time = 1.8
        elif subtitle_length_mode == 'relaxed':
            self.chars_per_line = max(chars_per_line, 18)
            self.min_display_time = 1.2
        
        logger.info(f"ğŸ“ å­—å¹•é•·åº¦é…ç½®: {subtitle_length_mode} - æ¯è¡Œ{self.chars_per_line}å­—ï¼Œæœ€å¤š{self.max_lines}è¡Œ")
        
        # å°å…¥æ‰€éœ€æ¨¡çµ„
        try:
            import whisper
            self.whisper = whisper
            logger.info(f"âœ… Whisper æ¨¡çµ„è¼‰å…¥æˆåŠŸï¼Œæ¨¡å‹å¤§å°: {model_size}")
        except ImportError:
            logger.error("âŒ ç„¡æ³•å°å…¥ Whisper æ¨¡çµ„")
            raise ImportError("éœ€è¦å®‰è£ openai-whisper: pip install openai-whisper")
        
        # ä¸­æ–‡è½‰æ›æ¨¡çµ„ï¼ˆå¯é¸ï¼‰
        try:
            import zhconv
            self.zhconv = zhconv
            logger.info("âœ… ä¸­æ–‡è½‰æ›æ¨¡çµ„è¼‰å…¥æˆåŠŸ")
        except ImportError:
            logger.warning("âš ï¸ ä¸­æ–‡è½‰æ›æ¨¡çµ„æœªå®‰è£ï¼Œå°‡è·³éç¹ç°¡è½‰æ›")
            self.zhconv = None
    
    
    def get_whisper_model(self):
        """ç²å– Whisper æ¨¡å‹å¯¦ä¾‹"""
        if self._whisper_model is None:
            try:
                logger.info(f"ğŸ”„ æ­£åœ¨è¼‰å…¥ Whisper æ¨¡å‹: {self.model_size}")
                self._whisper_model = self.whisper.load_model(self.model_size)
                logger.info(f"âœ… Whisper æ¨¡å‹è¼‰å…¥å®Œæˆ: {self.model_size}")
            except Exception as e:
                logger.error(f"âŒ è¼‰å…¥ Whisper æ¨¡å‹å¤±æ•—: {e}")
                raise e
        return self._whisper_model
    
    def transcribe_audio(self, audio_path: str) -> List[Dict]:
        """ä½¿ç”¨ Whisper è½‰éŒ„éŸ³é »ä¸¦ç²å–æ™‚é–“æˆ³"""
        try:
            model = self.get_whisper_model()
            logger.info(f"ğŸ™ï¸ é–‹å§‹è½‰éŒ„éŸ³é »: {audio_path}")
            
            result = model.transcribe(
                audio_path,
                word_timestamps=True,
                verbose=False
            )
            
            segments = result.get("segments", [])
            logger.info(f"âœ… éŸ³é »è½‰éŒ„å®Œæˆï¼Œç²å¾— {len(segments)} å€‹ç‰‡æ®µ")
            
            return segments
            
        except Exception as e:
            logger.error(f"âŒ éŸ³é »è½‰éŒ„å¤±æ•—: {e}")
            raise e
    
    def _smart_split_text_into_sentences(self, text: str) -> List[str]:
        """æ™ºèƒ½ä¸­æ–‡åˆ†å¥"""
        if not text:
            return []
        
        # ä¸­æ–‡å¥è™Ÿã€æ„Ÿå˜†è™Ÿã€å•è™Ÿç­‰
        sentence_endings = r'[ã€‚ï¼ï¼Ÿï¼›]'
        
        # å…ˆæŒ‰ä¸»è¦æ¨™é»åˆ†å‰²
        sentences = re.split(sentence_endings, text)
        
        # æ¸…ç†ä¸¦é‡çµ„å¥å­ï¼ˆä¿ç•™æ¨™é»ï¼‰
        result_sentences = []
        for i, sentence in enumerate(sentences):
            sentence = sentence.strip()
            if sentence:
                # é‡æ–°æ·»åŠ æ¨™é»ï¼ˆé™¤äº†æœ€å¾Œä¸€å€‹ç©ºå­—ç¬¦ä¸²ï¼‰
                if i < len(sentences) - 1:
                    # æŸ¥æ‰¾åŸæ–‡ä¸­å°æ‡‰çš„æ¨™é»
                    original_pos = sum(len(sentences[j]) for j in range(i + 1)) + i
                    if original_pos < len(text):
                        punct = text[original_pos]
                        sentence += punct
                result_sentences.append(sentence)
        
        # å¦‚æœåˆ†å¥å¤±æ•—ï¼ŒæŒ‰é€—è™Ÿåˆ†å‰²
        if len(result_sentences) <= 1:
            sentences = text.split('ï¼Œ')
            result_sentences = [s.strip() for s in sentences if s.strip()]
        
        logger.info(f"ğŸ“ æ–‡å­—åˆ†å¥å®Œæˆ: {len(result_sentences)} å€‹å¥å­")
        return result_sentences
    
    def _convert_chinese(self, text: str) -> str:
        """ä¸­æ–‡ç¹ç°¡è½‰æ›"""
        if not self.traditional_chinese or not self.zhconv:
            return text
        
        try:
            return self.zhconv.convert(text, 'zh-tw')
        except Exception as e:
            logger.warning(f"âš ï¸ ä¸­æ–‡è½‰æ›å¤±æ•—: {e}")
            return text
        
    def _generate_srt_content(self, segments: List[Dict]) -> str:
        """ç”Ÿæˆ SRT å­—å¹•å…§å®¹ï¼ˆæ”¯æ´é•·å­—å¹•åˆ‡åˆ†ï¼‰"""
        srt_content = ""
        subtitle_index = 1
        
        for segment in segments:
            start_time = segment["start"]
            end_time = segment["end"]
            text = segment["text"]
            
            # åˆ‡åˆ†éé•·çš„å­—å¹•
            split_subtitles = self._split_long_subtitle(text, start_time, end_time)
            
            for sub_segment in split_subtitles:
                srt_start_time = self._format_time(sub_segment["start"])
                srt_end_time = self._format_time(sub_segment["end"])
                sub_text = sub_segment["text"]
                
                srt_content += f"{subtitle_index}\n"
                srt_content += f"{srt_start_time} --> {srt_end_time}\n"
                srt_content += f"{sub_text}\n\n"
                subtitle_index += 1
        
        return srt_content
    
    def _split_long_subtitle(self, text: str, start_time: float, end_time: float) -> List[Dict]:
        """
        åˆ‡åˆ†éé•·çš„å­—å¹•
        
        Args:
            text: åŸå§‹å­—å¹•æ–‡å­—
            start_time: é–‹å§‹æ™‚é–“
            end_time: çµæŸæ™‚é–“
            
        Returns:
            åˆ‡åˆ†å¾Œçš„å­—å¹•ç‰‡æ®µåˆ—è¡¨
        """
        # ä½¿ç”¨é…ç½®çš„å­—å¹•é¡¯ç¤ºåƒæ•¸
        max_chars_per_line = self.chars_per_line
        max_lines = self.max_lines
        max_chars_total = max_chars_per_line * max_lines
        min_display_time = self.min_display_time
        
        # å¦‚æœæ–‡å­—ä¸è¶…éé™åˆ¶ï¼Œç›´æ¥è¿”å›
        if len(text) <= max_chars_total:
            formatted_text = self._format_subtitle_lines(text, max_chars_per_line)
            return [{
                "start": start_time,
                "end": end_time,
                "text": formatted_text
            }]
        
        # åˆ‡åˆ†é•·æ–‡å­—
        segments = []
        total_duration = end_time - start_time
        
        # æ™ºèƒ½åˆ†å¥ï¼šå„ªå…ˆæŒ‰æ¨™é»ç¬¦è™Ÿåˆ‡åˆ†
        sentences = self._smart_split_by_punctuation(text, max_chars_total)
        
        # è¨ˆç®—æ¯å€‹åˆ†æ®µçš„æ™‚é–“
        total_chars = sum(len(sentence) for sentence in sentences)
        current_time = start_time
        
        for i, sentence in enumerate(sentences):
            # æ ¹æ“šå­—å…ƒæ•¸æ¯”ä¾‹åˆ†é…æ™‚é–“
            if total_chars > 0:
                segment_duration = (len(sentence) / total_chars) * total_duration
            else:
                segment_duration = total_duration / len(sentences)
            
            # ç¢ºä¿æœ€å°é¡¯ç¤ºæ™‚é–“
            segment_duration = max(segment_duration, min_display_time)
            
            # è¨ˆç®—çµæŸæ™‚é–“
            segment_end_time = current_time + segment_duration
            
            # æœ€å¾Œä¸€å€‹ç‰‡æ®µå°é½ŠåŸå§‹çµæŸæ™‚é–“
            if i == len(sentences) - 1:
                segment_end_time = end_time
            
            # ç¢ºä¿æ™‚é–“ä¸æœƒå€’é€€
            if segment_end_time <= current_time:
                segment_end_time = current_time + min_display_time
            
            # é€²ä¸€æ­¥åˆ‡åˆ†éé•·çš„å¥å­ï¼ˆå¦‚æœå–®å¥ä»ç„¶å¤ªé•·ï¼‰
            if len(sentence) > max_chars_total:
                sub_segments = self._force_split_long_sentence(
                    sentence, current_time, segment_end_time, max_chars_total
                )
                segments.extend(sub_segments)
                current_time = sub_segments[-1]["end"]
            else:
                # æ ¼å¼åŒ–ç‚ºé›™è¡Œé¡¯ç¤º
                formatted_text = self._format_subtitle_lines(sentence, max_chars_per_line)
                segments.append({
                    "start": current_time,
                    "end": segment_end_time,
                    "text": formatted_text
                })
                current_time = segment_end_time
        
        return segments
    
    def _smart_split_by_punctuation(self, text: str, max_chars: int) -> List[str]:
        """æ ¹æ“šæ¨™é»ç¬¦è™Ÿæ™ºèƒ½åˆ‡åˆ†æ–‡å­—"""
        # ä¸­æ–‡æ¨™é»ç¬¦è™Ÿ
        punctuation_marks = ['ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼›', 'ï¼Œ', 'ã€', 'ï¼š']
        
        sentences = []
        current_sentence = ""
        
        for char in text:
            current_sentence += char
            
            # é‡åˆ°æ¨™é»ç¬¦è™Ÿä¸”é•·åº¦é©ä¸­æ™‚åˆ‡åˆ†
            if char in punctuation_marks and len(current_sentence.strip()) > 0:
                if len(current_sentence) <= max_chars:
                    sentences.append(current_sentence.strip())
                    current_sentence = ""
                # å¦‚æœåŠ ä¸Šæ¨™é»å¾Œä»ç„¶å¤ªé•·ï¼Œå…ˆåˆ‡åˆ†å‰é¢çš„éƒ¨åˆ†
                elif len(current_sentence) > max_chars:
                    # å›é€€åˆ°æ¨™é»å‰
                    pre_punct = current_sentence[:-1].strip()
                    if pre_punct:
                        sentences.append(pre_punct)
                    current_sentence = char  # ä¿ç•™æ¨™é»ç¬¦è™Ÿ
        
        # è™•ç†å‰©é¤˜æ–‡å­—
        if current_sentence.strip():
            sentences.append(current_sentence.strip())
        
        # åˆä½µéçŸ­çš„ç‰‡æ®µ
        return self._merge_short_segments(sentences, max_chars)
    
    def _merge_short_segments(self, sentences: List[str], max_chars: int) -> List[str]:
        """åˆä½µéçŸ­çš„ç‰‡æ®µ"""
        merged = []
        current = ""
        
        for sentence in sentences:
            # å¦‚æœåˆä½µå¾Œä¸è¶…éé™åˆ¶ï¼Œå‰‡åˆä½µ
            if len(current + sentence) <= max_chars:
                current += sentence
            else:
                # ä¿å­˜ç•¶å‰ç‰‡æ®µï¼Œé–‹å§‹æ–°ç‰‡æ®µ
                if current:
                    merged.append(current)
                current = sentence
        
        # æ·»åŠ æœ€å¾Œä¸€å€‹ç‰‡æ®µ
        if current:
            merged.append(current)
        
        return merged
    
    def _force_split_long_sentence(self, sentence: str, start_time: float, end_time: float, max_chars: int) -> List[Dict]:
        """å¼·åˆ¶åˆ‡åˆ†éé•·çš„å¥å­"""
        segments = []
        total_duration = end_time - start_time
        
        # æŒ‰æœ€å¤§å­—å…ƒæ•¸å¼·åˆ¶åˆ‡åˆ†
        parts = []
        for i in range(0, len(sentence), max_chars):
            parts.append(sentence[i:i + max_chars])
        
        # åˆ†é…æ™‚é–“
        current_time = start_time
        for i, part in enumerate(parts):
            # æ ¹æ“šå­—å…ƒæ•¸æ¯”ä¾‹åˆ†é…æ™‚é–“
            part_duration = (len(part) / len(sentence)) * total_duration
            part_end_time = current_time + part_duration
            
            # æœ€å¾Œä¸€å€‹ç‰‡æ®µå°é½ŠçµæŸæ™‚é–“
            if i == len(parts) - 1:
                part_end_time = end_time
            
            # æ ¼å¼åŒ–ç‚ºé›™è¡Œé¡¯ç¤º
            formatted_text = self._format_subtitle_lines(part, self.chars_per_line)
            segments.append({
                "start": current_time,
                "end": part_end_time,
                "text": formatted_text
            })
            
            current_time = part_end_time
        
        return segments
    
    def _format_subtitle_lines(self, text: str, max_chars_per_line: int) -> str:
        """å°‡æ–‡å­—æ ¼å¼åŒ–ç‚ºé©åˆçš„è¡Œæ•¸"""
        if len(text) <= max_chars_per_line:
            return text
        
        # å˜—è©¦åœ¨åˆé©çš„ä½ç½®æ–·è¡Œ
        words = list(text)  # ä¸­æ–‡æŒ‰å­—å…ƒè™•ç†
        lines = []
        current_line = ""
        
        for char in words:
            if len(current_line + char) <= max_chars_per_line:
                current_line += char
            else:
                if current_line:
                    lines.append(current_line)
                current_line = char
        
        # æ·»åŠ æœ€å¾Œä¸€è¡Œ
        if current_line:
            lines.append(current_line)
        
        # æœ€å¤šå…©è¡Œï¼Œå¦‚æœè¶…éå‰‡åˆä½µ
        if len(lines) > 2:
            # é‡æ–°åˆ†é…åˆ°å…©è¡Œ
            half_chars = len(text) // 2
            line1 = text[:half_chars]
            line2 = text[half_chars:]
            return f"{line1}\n{line2}"
        else:
            return "\n".join(lines)
    
    def _format_time(self, seconds: float) -> str:
        """å°‡ç§’æ•¸è½‰æ›ç‚º SRT æ™‚é–“æ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        seconds_remainder = seconds % 60
        milliseconds = int((seconds_remainder % 1) * 1000)
        seconds_int = int(seconds_remainder)
        
        return f"{hours:02d}:{minutes:02d}:{seconds_int:02d},{milliseconds:03d}"
    
    def generate_hybrid_subtitles(self, video_path: str, reference_texts: List[str]) -> str:
        """
        ç”Ÿæˆæ··åˆå­—å¹• - å®Œå…¨ä½¿ç”¨ç”¨æˆ¶è¼¸å…¥æ–‡å­—ï¼Œåƒ…å¾Whisperç²å–æ™‚é–“è»¸
        
        Args:
            video_path: è¦–é »æ–‡ä»¶è·¯å¾‘
            reference_texts: ç”¨æˆ¶æä¾›çš„åƒè€ƒæ–‡å­—åˆ—è¡¨ï¼ˆæ¯å€‹å…ƒç´ ä»£è¡¨ä¸€é ï¼‰
            
        Returns:
            SRT å­—å¹•æ–‡ä»¶è·¯å¾‘
        """
        try:
            logger.info(f"ğŸ¬ é–‹å§‹ç”Ÿæˆæ··åˆå­—å¹•ï¼Œè¦–é »: {video_path}")
            logger.info(f"ğŸ“„ åƒè€ƒæ–‡å­—é æ•¸: {len(reference_texts)}")
            
            # å¾è¦–é »æå–éŸ³é »
            audio_path = self._extract_audio_from_video(video_path)
            
            # ä½¿ç”¨ Whisper è½‰éŒ„éŸ³é »ç²å–æ™‚é–“æˆ³ï¼ˆåƒ…ç”¨æ–¼æ™‚é–“è»¸ï¼‰
            whisper_segments = self.transcribe_audio(audio_path)
            
            # ç›´æ¥æ˜ å°„ç”¨æˆ¶æ–‡å­—åˆ°æ™‚é–“è»¸ï¼ˆä¸é€²è¡ŒéŒ¯å­—æª¢æ¸¬æˆ–ä¿®æ­£ï¼‰
            mapped_segments = self._simple_map_user_text_to_timeline(whisper_segments, reference_texts)
            
            # ç”Ÿæˆ SRT å…§å®¹
            srt_content = self._generate_srt_content(mapped_segments)
            
            # ä¿å­˜ SRT æ–‡ä»¶
            srt_path = video_path.replace('.mp4', '_hybrid.srt')
            with open(srt_path, 'w', encoding='utf-8') as f:
                f.write(srt_content)
            
            logger.info(f"âœ… æ··åˆå­—å¹•ç”Ÿæˆå®Œæˆ: {srt_path}")
            
            # æ¸…ç†è‡¨æ™‚éŸ³é »æ–‡ä»¶
            if os.path.exists(audio_path):
                os.remove(audio_path)
            
            return srt_path
            
        except Exception as e:
            logger.error(f"âŒ æ··åˆå­—å¹•ç”Ÿæˆå¤±æ•—: {e}")
            raise e
    
    def _extract_audio_from_video(self, video_path: str) -> str:
        """å¾è¦–é »ä¸­æå–éŸ³é »"""
        try:
            # å‰µå»ºè‡¨æ™‚éŸ³é »æ–‡ä»¶
            audio_path = video_path.replace('.mp4', '_temp_audio.wav')
            
            # ä½¿ç”¨ ffmpeg æå–éŸ³é »
            cmd = [
                'ffmpeg', '-i', video_path,
                '-acodec', 'pcm_s16le',
                '-ar', '16000',
                '-ac', '1',
                '-y', audio_path
            ]
            
            logger.info(f"ğŸµ æ­£åœ¨æå–éŸ³é »: {video_path} -> {audio_path}")
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                raise Exception(f"FFmpeg æå–éŸ³é »å¤±æ•—: {result.stderr}")
            
            logger.info(f"âœ… éŸ³é »æå–å®Œæˆ: {audio_path}")
            return audio_path
            
        except Exception as e:
            logger.error(f"âŒ éŸ³é »æå–å¤±æ•—: {e}")
            raise e
    
    def _simple_map_user_text_to_timeline(self, whisper_segments: List[Dict], reference_texts) -> List[Dict]:
        """
        ç²¾ç¢ºæ˜ å°„ï¼šåˆ©ç”¨æ¨™é»ç¬¦è™Ÿåˆ‡å‰²ï¼Œå°‡Whisperå¥å­ä¸€å°ä¸€æ›¿æ›ç‚ºç”¨æˆ¶æ–‡å­—
        
        æµç¨‹ï¼š
        A. ç”¨æˆ¶è¼¸å…¥æ–‡å­— â†’ B. WhisperèªéŸ³è­˜åˆ¥ â†’ C. ç²å–æ™‚é–“æˆ³ â†’ 
        D. åˆ©ç”¨æ¨™é»ç¬¦è™Ÿåˆ‡å‰²å¥å­ï¼Œä¸€å°ä¸€æ›¿æ› â†’ E. ç”ŸæˆSRT â†’ F. åµŒå…¥è¦–é »
        """
        mapped_segments = []
        
        if not whisper_segments or not reference_texts:
            logger.warning("âš ï¸ Whisperç‰‡æ®µæˆ–ç”¨æˆ¶æ–‡å­—ç‚ºç©º")
            return mapped_segments
        
        # è™•ç†å–®ä¸€å­—ä¸²çš„æƒ…æ³
        if isinstance(reference_texts, str):
            reference_texts = [reference_texts]
        
        logger.info(f"ğŸ§  é–‹å§‹ç²¾ç¢ºæ˜ å°„ï¼š{len(reference_texts)} å€‹ç”¨æˆ¶æ–‡å­— â†’ {len(whisper_segments)} å€‹ Whisper ç‰‡æ®µ")
        
        # ç¬¬ä¸€æ­¥ï¼šå°‡æ‰€æœ‰ç”¨æˆ¶æ–‡å­—æŒ‰æ¨™é»ç¬¦è™Ÿåˆ‡å‰²æˆå¥å­
        all_user_sentences = []
        for page_index, page_text in enumerate(reference_texts):
            if page_text and page_text.strip():
                sentences = self._split_sentences_by_punctuation(page_text.strip())
                for sentence in sentences:
                    if sentence.strip():
                        all_user_sentences.append({
                            'text': sentence.strip(),
                            'page_index': page_index + 1
                        })
        
        logger.info(f"ğŸ“ ç”¨æˆ¶æ–‡å­—åˆ‡å‰²çµæœ: {len(all_user_sentences)} å€‹å¥å­")
        for i, sentence in enumerate(all_user_sentences):
            logger.info(f"  ç”¨æˆ¶å¥å­ {i+1}: '{sentence['text'][:30]}...'")
        
        # ç¬¬äºŒæ­¥ï¼šå°‡æ‰€æœ‰Whisperç‰‡æ®µä¹ŸæŒ‰æ¨™é»ç¬¦è™Ÿåˆ‡å‰²
        all_whisper_sentences = []
        for whisper_seg in whisper_segments:
            whisper_text = whisper_seg['text'].strip()
            # æª¢æŸ¥Whisperç‰‡æ®µæ˜¯å¦åŒ…å«æ¨™é»ç¬¦è™Ÿï¼Œå¦‚æœåŒ…å«å‰‡åˆ‡å‰²
            sentences = self._split_sentences_by_punctuation(whisper_text)
            
            if len(sentences) <= 1:
                # æ²’æœ‰æ¨™é»ç¬¦è™Ÿï¼Œæ•´æ®µä½œç‚ºä¸€å€‹å¥å­
                all_whisper_sentences.append({
                    'text': whisper_text,
                    'start': whisper_seg['start'],
                    'end': whisper_seg['end'],
                    'original_segment': whisper_seg
                })
            else:
                # æœ‰æ¨™é»ç¬¦è™Ÿï¼ŒæŒ‰å¥å­åˆ‡å‰²ä¸¦æŒ‰æ¯”ä¾‹åˆ†é…æ™‚é–“
                total_duration = whisper_seg['end'] - whisper_seg['start']
                sentence_count = len(sentences)
                time_per_sentence = total_duration / sentence_count
                
                for j, sentence in enumerate(sentences):
                    if sentence.strip():
                        start_time = whisper_seg['start'] + (j * time_per_sentence)
                        end_time = whisper_seg['start'] + ((j + 1) * time_per_sentence)
                        
                        all_whisper_sentences.append({
                            'text': sentence.strip(),
                            'start': start_time,
                            'end': end_time,
                            'original_segment': whisper_seg
                        })
        
        logger.info(f"ğŸ™ï¸ Whisperæ–‡å­—åˆ‡å‰²çµæœ: {len(all_whisper_sentences)} å€‹å¥å­")
        for i, sentence in enumerate(all_whisper_sentences):
            logger.info(f"  Whisperå¥å­ {i+1}: {sentence['start']:.2f}s-{sentence['end']:.2f}s: '{sentence['text'][:30]}...'")
        
        # ç¬¬ä¸‰æ­¥ï¼šä¸€å°ä¸€æ›¿æ› - ä½¿ç”¨Whisperçš„æ™‚é–“æˆ³ + ç”¨æˆ¶çš„æ–‡å­—
        mapping_count = min(len(all_user_sentences), len(all_whisper_sentences))
        logger.info(f"ğŸ”„ åŸ·è¡Œä¸€å°ä¸€æ˜ å°„ï¼Œå…± {mapping_count} å°")
        
        for i in range(mapping_count):
            user_sentence = all_user_sentences[i]
            whisper_sentence = all_whisper_sentences[i]
            
            # ä½¿ç”¨Whisperçš„ç²¾ç¢ºæ™‚é–“æˆ³ + ç”¨æˆ¶çš„æ–‡å­—å…§å®¹
            final_text = self._convert_chinese(user_sentence['text'])
            
            mapped_segments.append({
                "start": whisper_sentence['start'],      # âœ… ä½¿ç”¨Whisperæ™‚é–“æˆ³
                "end": whisper_sentence['end'],          # âœ… ä½¿ç”¨Whisperæ™‚é–“æˆ³
                "text": final_text,                      # âœ… ä½¿ç”¨ç”¨æˆ¶æ–‡å­—
                "source": "one_to_one_replacement",      # æ¨™è¨˜ç‚ºä¸€å°ä¸€æ›¿æ›
                "page_index": user_sentence['page_index'],
                "original_whisper": whisper_sentence['text']  # ä¿ç•™åŸå§‹Whisperæ–‡å­—ä¾›èª¿è©¦
            })
            
            logger.info(f"  ğŸ“ æ˜ å°„ {i+1}: {whisper_sentence['start']:.2f}s-{whisper_sentence['end']:.2f}s")
            logger.info(f"    åŸWhisper: '{whisper_sentence['text'][:25]}...'")
            logger.info(f"    æ›¿æ›ç”¨æˆ¶: '{final_text[:25]}...'")
        
        # è™•ç†å‰©é¤˜çš„å¥å­ï¼ˆå¦‚æœç”¨æˆ¶æ–‡å­—æ¯”Whisperå¤šï¼‰
        if len(all_user_sentences) > len(all_whisper_sentences):
            logger.warning(f"âš ï¸ ç”¨æˆ¶å¥å­æ¯”Whisperå¤š {len(all_user_sentences) - len(all_whisper_sentences)} å€‹ï¼Œå°‡è¢«å¿½ç•¥")
            for i in range(len(all_whisper_sentences), len(all_user_sentences)):
                logger.warning(f"  å¿½ç•¥ç”¨æˆ¶å¥å­: '{all_user_sentences[i]['text'][:30]}...'")
        
        # è™•ç†å‰©é¤˜çš„Whisperç‰‡æ®µï¼ˆå¦‚æœWhisperæ¯”ç”¨æˆ¶æ–‡å­—å¤šï¼‰
        elif len(all_whisper_sentences) > len(all_user_sentences):
            logger.warning(f"âš ï¸ Whisperå¥å­æ¯”ç”¨æˆ¶å¤š {len(all_whisper_sentences) - len(all_user_sentences)} å€‹ï¼Œå°‡ä¿ç•™åŸå§‹æ–‡å­—")
            for i in range(len(all_user_sentences), len(all_whisper_sentences)):
                whisper_sentence = all_whisper_sentences[i]
                
                mapped_segments.append({
                    "start": whisper_sentence['start'],
                    "end": whisper_sentence['end'],
                    "text": self._convert_chinese(whisper_sentence['text']),  # ä½¿ç”¨WhisperåŸå§‹æ–‡å­—
                    "source": "whisper_only",
                    "page_index": 0,
                    "original_whisper": whisper_sentence['text']
                })
                
                logger.warning(f"  ä¿ç•™Whisper: {whisper_sentence['start']:.2f}s-{whisper_sentence['end']:.2f}s: '{whisper_sentence['text'][:30]}...'")
        
        logger.info(f"âœ… ç²¾ç¢ºæ˜ å°„å®Œæˆï¼Œç”Ÿæˆ {len(mapped_segments)} å€‹å­—å¹•ç‰‡æ®µ")
        return mapped_segments
    
    def _split_sentences_by_punctuation(self, text: str) -> List[str]:
        """
        æ ¹æ“šæ¨™é»ç¬¦è™Ÿç²¾ç¢ºåˆ‡å‰²å¥å­
        
        Args:
            text: è¼¸å…¥æ–‡å­—
            
        Returns:
            å¥å­åˆ—è¡¨
        """
        if not text or not text.strip():
            return []
        
        # ä¸­æ–‡æ¨™é»ç¬¦è™Ÿåˆ—è¡¨
        sentence_endings = ['ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼›', 'â€¦', '!', '?', ';']
        
        sentences = []
        current_sentence = ""
        
        for char in text:
            current_sentence += char
            
            # å¦‚æœé‡åˆ°å¥å­çµæŸæ¨™é»
            if char in sentence_endings:
                if current_sentence.strip():
                    sentences.append(current_sentence.strip())
                current_sentence = ""
        
        # è™•ç†æœ€å¾Œä¸€å€‹å¥å­ï¼ˆæ²’æœ‰çµæŸæ¨™é»çš„æƒ…æ³ï¼‰
        if current_sentence.strip():
            sentences.append(current_sentence.strip())
        
        # éæ¿¾ç©ºå¥å­
        sentences = [s for s in sentences if s.strip()]
        
        return sentences

    def generate_subtitles_by_speech_rate(self, video_path: str, reference_texts: List[str]) -> str:
        """
        åŸºæ–¼èªé€Ÿè¨ˆç®—ç”Ÿæˆå­—å¹• - ç„¡éœ€Whisperï¼Œç›´æ¥ç”¨æ–‡ç¨¿å’ŒéŸ³é »æ™‚é•·è¨ˆç®—
        
        Args:
            video_path: è¦–é »æ–‡ä»¶è·¯å¾‘
            reference_texts: ç”¨æˆ¶æä¾›çš„åƒè€ƒæ–‡å­—åˆ—è¡¨
            
        Returns:
            SRT å­—å¹•æ–‡ä»¶è·¯å¾‘
        """
        try:
            logger.info(f"ğŸ“Š é–‹å§‹åŸºæ–¼èªé€Ÿç”Ÿæˆå­—å¹•ï¼Œè¦–é »: {video_path}")
            logger.info(f"ğŸ“„ åƒè€ƒæ–‡å­—é æ•¸: {len(reference_texts)}")
            
            # å¾è¦–é »æå–éŸ³é »ä¸¦ç²å–æ™‚é•·
            audio_path = self._extract_audio_from_video(video_path)
            audio_duration = self._get_audio_duration(audio_path)
            
            logger.info(f"ğŸµ éŸ³é »æ™‚é•·: {audio_duration:.2f} ç§’")
            
            # åˆä½µæ‰€æœ‰æ–‡å­—
            full_text = "\n".join(reference_texts) if isinstance(reference_texts, list) else reference_texts
            
            # è¨ˆç®—èªé€Ÿ
            speech_rate = self._calculate_speech_rate(full_text, audio_duration)
            logger.info(f"ğŸ“ˆ è¨ˆç®—èªé€Ÿ: {speech_rate:.2f} å­—/ç§’")
            
            # æŒ‰å¥å­åˆ‡å‰²æ–‡ç¨¿
            sentences = []
            for page_index, page_text in enumerate(reference_texts):
                if page_text and page_text.strip():
                    page_sentences = self._split_sentences_by_punctuation(page_text.strip())
                    for sentence in page_sentences:
                        if sentence.strip():
                            sentences.append({
                                'text': sentence.strip(),
                                'page_index': page_index + 1
                            })
            
            logger.info(f"ğŸ“ æ–‡ç¨¿åˆ‡å‰²: {len(sentences)} å€‹å¥å­")
            
            # æ ¹æ“šèªé€Ÿåˆ†é…æ™‚é–“æˆ³
            timestamped_segments = self._assign_timestamps_by_speech_rate(sentences, speech_rate)
            
            # èª¿æ•´æ™‚é–“æˆ³ç¢ºä¿ä¸è¶…éç¸½æ™‚é•·
            adjusted_segments = self._adjust_timestamps_to_duration(timestamped_segments, audio_duration)
            
            # ç”Ÿæˆ SRT å…§å®¹
            srt_content = self._generate_srt_content(adjusted_segments)
            
            # ä¿å­˜ SRT æ–‡ä»¶
            srt_path = video_path.replace('.mp4', '_speech_rate.srt')
            with open(srt_path, 'w', encoding='utf-8') as f:
                f.write(srt_content)
            
            logger.info(f"âœ… åŸºæ–¼èªé€Ÿçš„å­—å¹•ç”Ÿæˆå®Œæˆ: {srt_path}")
            
            # æ¸…ç†è‡¨æ™‚éŸ³é »æ–‡ä»¶
            if os.path.exists(audio_path):
                os.remove(audio_path)
            
            return srt_path
            
        except Exception as e:
            logger.error(f"âŒ åŸºæ–¼èªé€Ÿçš„å­—å¹•ç”Ÿæˆå¤±æ•—: {e}")
            raise e
    
    def _get_audio_duration(self, audio_path: str) -> float:
        """ç²å–éŸ³é »æ–‡ä»¶æ™‚é•·"""
        try:
            cmd = ['ffprobe', '-v', 'error', '-show_entries', 
                   'format=duration', '-of', 'csv=p=0', audio_path]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                raise Exception(f"FFprobe ç²å–æ™‚é•·å¤±æ•—: {result.stderr}")
            
            duration = float(result.stdout.strip())
            logger.info(f"ğŸµ éŸ³é »æ™‚é•·: {duration:.2f} ç§’")
            return duration
            
        except Exception as e:
            logger.error(f"âŒ ç²å–éŸ³é »æ™‚é•·å¤±æ•—: {e}")
            # å‚™ç”¨æ–¹æ³•ï¼šå˜—è©¦ä½¿ç”¨ ffmpeg
            try:
                cmd = ['ffmpeg', '-i', audio_path, '-f', 'null', '-']
                result = subprocess.run(cmd, capture_output=True, text=True)
                
                # å¾ stderr ä¸­è§£ææ™‚é•·
                import re
                duration_match = re.search(r'time=(\d{2}):(\d{2}):(\d{2}\.\d{2})', result.stderr)
                if duration_match:
                    hours, minutes, seconds = duration_match.groups()
                    total_seconds = int(hours) * 3600 + int(minutes) * 60 + float(seconds)
                    logger.info(f"ğŸµ éŸ³é »æ™‚é•·ï¼ˆå‚™ç”¨æ–¹æ³•ï¼‰: {total_seconds:.2f} ç§’")
                    return total_seconds
                else:
                    raise Exception("ç„¡æ³•è§£æéŸ³é »æ™‚é•·")
                    
            except Exception as backup_e:
                logger.error(f"âŒ å‚™ç”¨æ–¹æ³•ä¹Ÿå¤±æ•—: {backup_e}")
                raise e
    
    def _count_effective_characters(self, text: str) -> int:
        """è¨ˆç®—æœ‰æ•ˆå­—æ•¸ï¼ˆæ’é™¤æ¨™é»å’Œç©ºæ ¼ï¼‰"""
        import re
        effective_chars = len(re.sub(r'[^\w]', '', text))
        return effective_chars
    
    def _calculate_pause_time(self, text: str) -> float:
        """è¨ˆç®—æ–‡æœ¬ä¸­æ¨™é»ç¬¦è™Ÿçš„ç¸½åœé “æ™‚é–“"""
        punctuation_pauses = {
            'ã€‚': 0.5, 'ï¼': 0.5, 'ï¼Ÿ': 0.5, 'ï¼›': 0.3,
            'ï¼Œ': 0.2, 'ã€': 0.15, 'ï¼š': 0.25, 'â€¦': 0.4
        }
        
        total_pause_time = 0
        for punct, pause_duration in punctuation_pauses.items():
            count = text.count(punct)
            total_pause_time += count * pause_duration
        
        return total_pause_time
    
    def _calculate_speech_rate(self, text: str, duration: float) -> float:
        """è¨ˆç®—å¯¦éš›èªé€Ÿï¼ˆå­—/ç§’ï¼‰"""
        # ä½¿ç”¨å¹«åŠ©æ–¹æ³•è¨ˆç®—æœ‰æ•ˆå­—æ•¸
        effective_chars = self._count_effective_characters(text)
        
        # ä½¿ç”¨å¹«åŠ©æ–¹æ³•è¨ˆç®—ç¸½åœé “æ™‚é–“
        total_pause_time = self._calculate_pause_time(text)
        
        # è¨ˆç®—æ·¨èªéŸ³æ™‚é–“ï¼ˆæ‰£é™¤åœé “ï¼‰
        net_speech_time = duration - total_pause_time
        
        # ç¢ºä¿æ·¨èªéŸ³æ™‚é–“ä¸æœƒå¤ªå°
        if net_speech_time <= 0:
            net_speech_time = duration * 0.8  # ä¿åº•80%çš„æ™‚é–“ç”¨æ–¼èªªè©±
        
        speech_rate = effective_chars / net_speech_time
        
        logger.info(f"ğŸ“Š æ–‡å­—çµ±è¨ˆ: {effective_chars} å€‹æœ‰æ•ˆå­—ç¬¦")
        logger.info(f"â±ï¸ é ä¼°åœé “æ™‚é–“: {total_pause_time:.2f} ç§’")
        logger.info(f"ğŸ—£ï¸ æ·¨èªéŸ³æ™‚é–“: {net_speech_time:.2f} ç§’")
        logger.info(f"ğŸ“ˆ è¨ˆç®—èªé€Ÿ: {speech_rate:.2f} å­—/ç§’")
        
        return speech_rate
    
    def _assign_timestamps_by_speech_rate(self, sentences: List[Dict], speech_rate: float) -> List[Dict]:
        """æ ¹æ“šèªé€Ÿåˆ†é…æ™‚é–“æˆ³"""
        segments = []
        current_time = 0.0
        
        # æ¨™é»ç¬¦è™Ÿåœé “æ™‚é–“è¨­å®š
        punctuation_pauses = {
            'ã€‚': 0.5, 'ï¼': 0.5, 'ï¼Ÿ': 0.5, 'ï¼›': 0.3,
            'ï¼Œ': 0.2, 'ã€': 0.15, 'ï¼š': 0.25, 'â€¦': 0.4
        }
        
        for i, sentence_info in enumerate(sentences):
            sentence = sentence_info['text']
            
            # è¨ˆç®—å¥å­çš„æœ‰æ•ˆå­—æ•¸
            import re
            effective_chars = len(re.sub(r'[^\w]', '', sentence))
            
            # è¨ˆç®—èªªè©±æ™‚é–“
            speech_time = effective_chars / speech_rate if effective_chars > 0 else 0.1
            
            # è¨ˆç®—åœé “æ™‚é–“
            pause_time = 0.1  # é è¨­åœé “
            for punct, pause_duration in punctuation_pauses.items():
                if sentence.endswith(punct):
                    pause_time = pause_duration
                    break
            
            # ç¸½æ™‚é–“ = èªªè©±æ™‚é–“ + åœé “æ™‚é–“
            total_duration = speech_time + pause_time
            end_time = current_time + total_duration
            
            # æ‡‰ç”¨ç¹ç°¡è½‰æ›
            final_text = self._convert_chinese(sentence)
            
            segments.append({
                'start': current_time,
                'end': end_time,
                'text': final_text,
                'effective_chars': effective_chars,
                'speech_time': speech_time,
                'pause_time': pause_time,
                'source': 'speech_rate_calculation',
                'page_index': sentence_info['page_index']
            })
            
            logger.info(f"  ğŸ“ å¥å­ {i+1}: {current_time:.2f}s-{end_time:.2f}s ({effective_chars}å­—, {speech_time:.2f}s+{pause_time:.2f}s)")
            logger.info(f"     å…§å®¹: '{final_text[:30]}...'")
            
            current_time = end_time
        
        return segments
    
    def _adjust_timestamps_to_duration(self, segments: List[Dict], target_duration: float) -> List[Dict]:
        """èª¿æ•´æ™‚é–“æˆ³ä»¥åŒ¹é…ç›®æ¨™æ™‚é•·"""
        if not segments:
            return segments
        
        # è¨ˆç®—ç•¶å‰ç¸½æ™‚é•·
        current_total = segments[-1]['end']
        
        logger.info(f"âš–ï¸ æ™‚é–“èª¿æ•´: è¨ˆç®—æ™‚é•· {current_total:.2f}s â†’ ç›®æ¨™æ™‚é•· {target_duration:.2f}s")
        
        # å¦‚æœæ™‚é–“å·®ç•°è¶…é1ç§’ï¼Œé€²è¡Œç¸®æ”¾èª¿æ•´
        if abs(current_total - target_duration) > 1.0:
            scale_factor = target_duration / current_total
            logger.info(f"ğŸ”§ æ‡‰ç”¨ç¸®æ”¾æ¯”ä¾‹: {scale_factor:.3f}")
            
            for segment in segments:
                segment['start'] *= scale_factor
                segment['end'] *= scale_factor
            
            logger.info(f"âœ… æ™‚é–“æˆ³èª¿æ•´å®Œæˆï¼Œæœ€çµ‚æ™‚é•·: {segments[-1]['end']:.2f}s")
        else:
            logger.info("âœ… æ™‚é–“æˆ³ç„¡éœ€èª¿æ•´ï¼Œèª¤å·®åœ¨å¯æ¥å—ç¯„åœå…§")
        
        return segments

    def embed_subtitles_in_video(self, input_video_path: str, srt_path: str, output_video_path: str, style: str = "default") -> bool:
        """å°‡å­—å¹•åµŒå…¥è¦–é »"""
        try:
            logger.info(f"ğŸ¬ é–‹å§‹åµŒå…¥å­—å¹•: {input_video_path}")
            
            # ç²å–å¯ç”¨å­—é«”
            font_name = get_available_chinese_font()
            logger.info(f"ğŸ”¤ ä½¿ç”¨å­—é«”: {font_name}")
            
            # æ­£è¦åŒ–è·¯å¾‘ä¸¦è™•ç†Windowsè·¯å¾‘åˆ†éš”ç¬¦å•é¡Œ
            normalized_srt_path = srt_path.replace('\\', '/').replace(':', '\\:')
            
            # æª¢æŸ¥æª”æ¡ˆç‹€æ…‹
            logger.info(f"ğŸ“ è¼¸å…¥è¦–é »: {input_video_path} (å­˜åœ¨: {os.path.exists(input_video_path)})")
            logger.info(f"ğŸ“ å­—å¹•æª”æ¡ˆ: {srt_path} (å­˜åœ¨: {os.path.exists(srt_path)})")
            logger.info(f"ğŸ“ è¼¸å‡ºè·¯å¾‘: {output_video_path}")
            
            # æª¢æŸ¥SRTæª”æ¡ˆå…§å®¹
            if os.path.exists(srt_path):
                try:
                    with open(srt_path, 'r', encoding='utf-8') as f:
                        srt_content = f.read()
                        srt_lines = srt_content.strip().split('\n')
                        logger.info(f"ğŸ“ SRTæª”æ¡ˆè¡Œæ•¸: {len(srt_lines)}")
                        logger.info(f"ğŸ“ SRTæª”æ¡ˆå‰5è¡Œ: {srt_lines[:5]}")
                        if len(srt_content) == 0:
                            logger.error("âŒ SRTæª”æ¡ˆç‚ºç©º")
                            return False
                except Exception as e:
                    logger.error(f"âŒ ç„¡æ³•è®€å–SRTæª”æ¡ˆ: {e}")
                    return False
            
            # å˜—è©¦ä¸åŒçš„å­—å¹•åµŒå…¥æ–¹æ³•
            def try_subtitle_methods():
                methods = []
                
                # æ–¹æ³•1: ä½¿ç”¨å‹•æ…‹å­—é«”çš„å®Œæ•´æ¨£å¼
                if font_name and not font_name.startswith("/"):  # å­—é«”åç¨±è€Œéè·¯å¾‘
                    style_with_font = f"force_style='FontName={font_name},FontSize=18,PrimaryColour=&Hffffff,SecondaryColour=&Hffffff,OutlineColour=&H0,BackColour=&H80000000,Bold=1,Italic=0,Underline=0,StrikeOut=0,ScaleX=100,ScaleY=100,Spacing=0,Angle=0,BorderStyle=1,Outline=2,Shadow=0,Alignment=2,MarginL=10,MarginR=10,MarginV=10'"
                    methods.append(("å®Œæ•´æ¨£å¼", f"subtitles='{normalized_srt_path}':{style_with_font}"))
                
                # æ–¹æ³•2: ç°¡åŒ–æ¨£å¼
                simple_style = "force_style='FontSize=18,PrimaryColour=&Hffffff,OutlineColour=&H0,Bold=1,Outline=2,Alignment=2'"
                methods.append(("ç°¡åŒ–æ¨£å¼", f"subtitles='{normalized_srt_path}':{simple_style}"))
                
                # æ–¹æ³•3: æœ€åŸºæœ¬çš„å­—å¹•
                methods.append(("åŸºæœ¬å­—å¹•", f"subtitles='{normalized_srt_path}'"))
                
                return methods
            
            # å˜—è©¦ä¸åŒçš„å­—å¹•æ–¹æ³•
            subtitle_methods = try_subtitle_methods()
            result = None
            
            for method_name, vf_option in subtitle_methods:
                logger.info(f"ğŸ¬ å˜—è©¦{method_name}æ–¹æ³•...")
                
                cmd = [
                    'ffmpeg',
                    '-i', input_video_path,
                    '-vf', vf_option,
                    '-c:a', 'copy',
                    '-y', output_video_path
                ]
                
                logger.info(f"ğŸ“‹ FFmpeg å‘½ä»¤: {' '.join(cmd)}")
                
                try:
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
                    logger.info(f"ğŸ¬ {method_name} åŸ·è¡Œå®Œç•¢ - è¿”å›ç¢¼: {result.returncode}")
                    
                    if result.returncode == 0:
                        logger.info(f"âœ… {method_name} æˆåŠŸ!")
                        break
                    else:
                        logger.warning(f"âš ï¸ {method_name} å¤±æ•—: {result.stderr}")
                        # æª¢æŸ¥æ˜¯å¦æ˜¯å­—é«”ç›¸é—œéŒ¯èª¤
                        if "fontselect" not in result.stderr and "Glyph" not in result.stderr:
                            # éå­—é«”éŒ¯èª¤ï¼Œåœæ­¢å˜—è©¦å…¶ä»–æ–¹æ³•
                            break
                        
                except subprocess.TimeoutExpired:
                    logger.error(f"âŒ {method_name} åŸ·è¡Œè¶…æ™‚")
                    continue
                except Exception as e:
                    logger.error(f"âŒ {method_name} åŸ·è¡Œç•°å¸¸: {e}")
                    continue
            
            # å¦‚æœæ‰€æœ‰å­—å¹•åµŒå…¥æ–¹æ³•éƒ½å¤±æ•—ï¼Œæœ€å¾Œå˜—è©¦å¤–éƒ¨å­—å¹•
            if not result or result.returncode != 0:
                logger.info("ğŸ”„ æ‰€æœ‰å­—å¹•åµŒå…¥æ–¹æ³•å¤±æ•—ï¼Œå˜—è©¦å¤–éƒ¨å­—å¹•ä½œç‚ºæœ€å¾Œæ‰‹æ®µ...")
                fallback_cmd = [
                    'ffmpeg',
                    '-i', input_video_path,
                    '-i', srt_path,
                    '-c', 'copy',
                    '-c:s', 'mov_text',
                    '-y', output_video_path
                ]
                
                logger.info(f"ğŸ“‹ å¤–éƒ¨å­—å¹•å‘½ä»¤: {' '.join(fallback_cmd)}")
                try:
                    result = subprocess.run(fallback_cmd, capture_output=True, text=True, timeout=300)
                    logger.info(f"ğŸ”§ å¤–éƒ¨å­—å¹•åŸ·è¡Œå®Œç•¢ - è¿”å›ç¢¼: {result.returncode}")
                    if result.stdout:
                        logger.info(f"ğŸ“ å¤–éƒ¨å­—å¹•æ¨™æº–è¼¸å‡º: {result.stdout}")
                    if result.stderr:
                        logger.warning(f"âš ï¸ å¤–éƒ¨å­—å¹•æ¨™æº–éŒ¯èª¤: {result.stderr}")
                except Exception as e:
                    logger.error(f"âŒ å¤–éƒ¨å­—å¹•åŸ·è¡Œç•°å¸¸: {e}")
                    return False
            
            # æœ€çµ‚æª¢æŸ¥
            if not result or result.returncode != 0:
                logger.error("âŒ æ‰€æœ‰å­—å¹•åµŒå…¥æ–¹æ³•éƒ½å¤±æ•—äº†")
                return False
            
            # æª¢æŸ¥è¼¸å‡ºæª”æ¡ˆæ˜¯å¦çœŸçš„å­˜åœ¨
            if not os.path.exists(output_video_path):
                logger.error(f"âŒ è¼¸å‡ºè¦–é »æª”æ¡ˆä¸å­˜åœ¨: {output_video_path}")
                return False
            
            output_size = os.path.getsize(output_video_path)
            logger.info(f"âœ… å­—å¹•åµŒå…¥å®Œæˆ: {output_video_path} (å¤§å°: {output_size/1024/1024:.2f} MB)")
            return True
            
        except subprocess.TimeoutExpired:
            logger.error("âŒ FFmpeg åŸ·è¡Œè¶…æ™‚ (5åˆ†é˜)")
            return False
        except Exception as e:
            logger.error(f"âŒ å­—å¹•åµŒå…¥å¤±æ•—: {e}")
            return False
